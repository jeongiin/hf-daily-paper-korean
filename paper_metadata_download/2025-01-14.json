[
    "{'paper': {'id': '2501.07301', 'authors': [{'_id': '6785e601117627fe711f8dd8', 'user': {'_id': '64704e973601bb7b06643e98', 'avatarUrl': '/avatars/52e51f4d1be6769e4397b8be2799cf32.svg', 'isPro': False, 'fullname': 'Zhang', 'user': 'Zhenru', 'type': 'user'}, 'name': 'Zhenru Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:48:52.704Z', 'hidden': False}, {'_id': '6785e601117627fe711f8dd9', 'user': {'_id': '610b70452719facd4ea85e28', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/610b70452719facd4ea85e28/S7nMy7D0Rxq0VIVblhYDG.jpeg', 'isPro': False, 'fullname': 'Chujie Zheng', 'user': 'chujiezheng', 'type': 'user'}, 'name': 'Chujie Zheng', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-14T08:28:43.769Z', 'hidden': False}, {'_id': '6785e601117627fe711f8dda', 'user': {'_id': '671f2a2ab02f88b7e2385105', 'avatarUrl': '/avatars/a97e2f983c8290b72eeb03e2bdcaf085.svg', 'isPro': False, 'fullname': 'Yangzhen Wu', 'user': 'wuyangzhen', 'type': 'user'}, 'name': 'Yangzhen Wu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:49:01.963Z', 'hidden': False}, {'_id': '6785e601117627fe711f8ddb', 'user': {'_id': '64b93578ee257c3a4cfceed1', 'avatarUrl': '/avatars/e6188562254f75a09b4048b800860016.svg', 'isPro': False, 'fullname': 'Beichen Zhang', 'user': 'BeichenZhang', 'type': 'user'}, 'name': 'Beichen Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:49:43.861Z', 'hidden': False}, {'_id': '6785e601117627fe711f8ddc', 'user': {'_id': '649a52e5de0fb7f3f499e583', 'avatarUrl': '/avatars/25f6106fa168ae57ad5cd8ef55c70d31.svg', 'isPro': False, 'fullname': 'Runji Lin', 'user': 'RunjiLin', 'type': 'user'}, 'name': 'Runji Lin', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:49:56.685Z', 'hidden': False}, {'_id': '6785e601117627fe711f8ddd', 'user': {'_id': '6438b43ab2ea24b52ebac2b9', 'avatarUrl': '/avatars/84133cd719a4b1e2f5c1a74178425f86.svg', 'isPro': False, 'fullname': 'Bowen Yu', 'user': 'bwy', 'type': 'user'}, 'name': 'Bowen Yu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:50:12.316Z', 'hidden': False}, {'_id': '6785e601117627fe711f8dde', 'user': {'_id': '6434d4989bd5a84b5dd0b0f5', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg', 'isPro': False, 'fullname': 'Dayiheng Liu', 'user': 'Losin94', 'type': 'user'}, 'name': 'Dayiheng Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:50:18.536Z', 'hidden': False}, {'_id': '6785e601117627fe711f8ddf', 'user': {'_id': '602f88f5e8149a962412a667', 'avatarUrl': '/avatars/b78f0e583df8e5d5e3365934fe5f4900.svg', 'isPro': False, 'fullname': 'Zhou', 'user': 'Jingren', 'type': 'user'}, 'name': 'Jingren Zhou', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:50:29.301Z', 'hidden': False}, {'_id': '6785e601117627fe711f8de0', 'user': {'_id': '620760a26e3b7210c2ff1943', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg', 'isPro': False, 'fullname': 'Junyang Lin', 'user': 'JustinLin610', 'type': 'user'}, 'name': 'Junyang Lin', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:50:35.067Z', 'hidden': False}], 'publishedAt': '2025-01-13T13:10:16.000Z', 'title': 'The Lessons of Developing Process Reward Models in Mathematical\\n  Reasoning', 'summary': 'Process Reward Models (PRMs) emerge as a promising approach for process\\nsupervision in mathematical reasoning of Large Language Models (LLMs), which\\naim to identify and mitigate intermediate errors in the reasoning processes.\\nHowever, the development of effective PRMs faces significant challenges,\\nparticularly in data annotation and evaluation methodologies. In this paper,\\nthrough extensive experiments, we demonstrate that commonly used Monte Carlo\\n(MC) estimation-based data synthesis for PRMs typically yields inferior\\nperformance and generalization compared to LLM-as-a-judge and human annotation\\nmethods. MC estimation relies on completion models to evaluate current-step\\ncorrectness, leading to inaccurate step verification. Furthermore, we identify\\npotential biases in conventional Best-of-N (BoN) evaluation strategies for\\nPRMs: (1) The unreliable policy models generate responses with correct answers\\nbut flawed processes, leading to a misalignment between the evaluation criteria\\nof BoN and the PRM objectives of process verification. (2) The tolerance of\\nPRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a\\nsignificant proportion of minimum scores concentrated on the final answer\\nsteps, revealing the shift from process to outcome-based assessment in BoN\\nOptimized PRMs. To address these challenges, we develop a consensus filtering\\nmechanism that effectively integrates MC estimation with LLM-as-a-judge and\\nadvocates a more comprehensive evaluation framework that combines\\nresponse-level and step-level metrics. Based on the mechanisms, we\\nsignificantly improve both model performance and data efficiency in the BoN\\nevaluation and the step-wise error identification task. Finally, we release a\\nnew state-of-the-art PRM that outperforms existing open-source alternatives and\\nprovides practical guidelines for future research in building process\\nsupervision models.', 'upvotes': 38, 'discussionId': '6785e602117627fe711f8e15'}, 'publishedAt': '2025-01-13T23:23:11.463Z', 'title': 'The Lessons of Developing Process Reward Models in Mathematical Reasoning', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07301.png', 'numComments': 3, 'submittedBy': {'_id': '610b70452719facd4ea85e28', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/610b70452719facd4ea85e28/S7nMy7D0Rxq0VIVblhYDG.jpeg', 'fullname': 'Chujie Zheng', 'name': 'chujiezheng', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 26}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.06425', 'authors': [{'_id': '6785ce62cb1fc2728334a5e2', 'user': {'_id': '647bf082aba7062fe5c51ca9', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg', 'isPro': False, 'fullname': 'Yifan Zhang', 'user': 'yifAI', 'type': 'user'}, 'name': 'Yifan Zhang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-14T08:28:51.600Z', 'hidden': False}, {'_id': '6785ce62cb1fc2728334a5e3', 'name': 'Yifeng Liu', 'hidden': False}, {'_id': '6785ce62cb1fc2728334a5e4', 'name': 'Huizhuo Yuan', 'hidden': False}, {'_id': '6785ce62cb1fc2728334a5e5', 'user': {'_id': '649014b91d71e55664838d2d', 'avatarUrl': '/avatars/f0e0f2830c5cb7428cbbc9634d95c34b.svg', 'isPro': False, 'fullname': 'Zhen Qin', 'user': 'zhenqincn', 'type': 'user'}, 'name': 'Zhen Qin', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:51:32.418Z', 'hidden': True}, {'_id': '6785ce62cb1fc2728334a5e6', 'name': 'Yang Yuan', 'hidden': False}, {'_id': '6785ce62cb1fc2728334a5e7', 'user': {'_id': '64c039128e2612254356bba5', 'avatarUrl': '/avatars/06cc76feebba0cc80ebb8f4ff86f6d9b.svg', 'isPro': False, 'fullname': 'Quanquan Gu', 'user': 'thughost', 'type': 'user'}, 'name': 'Quanquan Gu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T08:52:03.941Z', 'hidden': False}, {'_id': '6785ce62cb1fc2728334a5e8', 'name': 'Andrew Chi-Chih Yao', 'hidden': False}], 'publishedAt': '2025-01-11T03:37:10.000Z', 'title': 'Tensor Product Attention Is All You Need', 'summary': 'Scaling language models to handle longer input sequences typically\\nnecessitates large key-value (KV) caches, resulting in substantial memory\\noverhead during inference. In this paper, we propose Tensor Product Attention\\n(TPA), a novel attention mechanism that uses tensor decompositions to represent\\nqueries, keys, and values compactly, significantly shrinking KV cache size at\\ninference time. By factorizing these representations into contextual low-rank\\ncomponents (contextual factorization) and seamlessly integrating with RoPE, TPA\\nachieves improved model quality alongside memory efficiency. Based on TPA, we\\nintroduce the Tensor ProducT ATTenTion Transformer (T6), a new model\\narchitecture for sequence modeling. Through extensive empirical evaluation of\\nlanguage modeling tasks, we demonstrate that T6 exceeds the performance of\\nstandard Transformer baselines including MHA, MQA, GQA, and MLA across various\\nmetrics, including perplexity and a range of renowned evaluation benchmarks.\\nNotably, TPAs memory efficiency enables the processing of significantly longer\\nsequences under fixed resource constraints, addressing a critical scalability\\nchallenge in modern language models. The code is available at\\nhttps://github.com/tensorgi/T6.', 'upvotes': 30, 'discussionId': '6785ce63cb1fc2728334a639'}, 'publishedAt': '2025-01-13T23:22:48.009Z', 'title': 'Tensor Product Attention Is All You Need', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/647bf082aba7062fe5c51ca9/y_7bf_BI9HbuGGrP0cJfU.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06425.png', 'numComments': 2, 'submittedBy': {'_id': '647bf082aba7062fe5c51ca9', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg', 'fullname': 'Yifan Zhang', 'name': 'yifAI', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 9}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.06252', 'authors': [{'_id': '6785e78b117627fe712005c9', 'user': {'_id': '644b983f0fbe4830f192c4f5', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/644b983f0fbe4830f192c4f5/4eX4OS0gnXGqLu3eaMml_.png', 'isPro': False, 'fullname': 'Qi Sun', 'user': 'lfsm', 'type': 'user'}, 'name': 'Qi Sun', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-14T09:11:43.467Z', 'hidden': False}, {'_id': '6785e78b117627fe712005ca', 'user': {'_id': '65ba6db23a03c2490a342647', 'avatarUrl': '/avatars/92221b08e679b2944c9c78f079da9fc6.svg', 'isPro': False, 'fullname': 'Edoardo Cetin', 'user': 'edoarc', 'type': 'user'}, 'name': 'Edoardo Cetin', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:07:24.416Z', 'hidden': False}, {'_id': '6785e78b117627fe712005cb', 'user': {'_id': '63285beda4102056bc198395', 'avatarUrl': '/avatars/6c936818a3814c1c32a8eaae8b8cb6d6.svg', 'isPro': False, 'fullname': 'yujin tang', 'user': 'tyj2022', 'type': 'user'}, 'name': 'Yujin Tang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-14T09:09:55.298Z', 'hidden': False}], 'publishedAt': '2025-01-09T01:19:21.000Z', 'title': 'Transformer^2: Self-adaptive LLMs', 'summary': 'Self-adaptive large language models (LLMs) aim to solve the challenges posed\\nby traditional fine-tuning methods, which are often computationally intensive\\nand static in their ability to handle diverse tasks. We introduce \\\\implname, a\\nnovel self-adaptation framework that adapts LLMs for unseen tasks in real-time\\nby selectively adjusting only the singular components of their weight matrices.\\nDuring inference, \\\\implname employs a two-pass mechanism: first, a dispatch\\nsystem identifies the task properties, and then task-specific \"expert\" vectors,\\ntrained using reinforcement learning, are dynamically mixed to obtain targeted\\nbehavior for the incoming prompt. Our method outperforms ubiquitous approaches\\nsuch as LoRA, with fewer parameters and greater efficiency. \\\\implname\\ndemonstrates versatility across different LLM architectures and modalities,\\nincluding vision-language tasks. \\\\implname represents a significant leap\\nforward, offering a scalable, efficient solution for enhancing the adaptability\\nand task-specific performance of LLMs, paving the way for truly dynamic,\\nself-organizing AI systems.', 'upvotes': 15, 'discussionId': '6785e78b117627fe71200618'}, 'publishedAt': '2025-01-13T23:27:12.322Z', 'title': '$\\\\text{Transformer}^2$: Self-adaptive LLMs', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06252.png', 'numComments': 5, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5645}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.06173', 'authors': [{'_id': '678604c71f54791d52bebe30', 'user': {'_id': '64b5ba6060274cbb296d6288', 'avatarUrl': '/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg', 'isPro': False, 'fullname': 'Junfei Xiao', 'user': 'lambertxiao', 'type': 'user'}, 'name': 'Junfei Xiao', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-14T08:28:41.422Z', 'hidden': False}, {'_id': '678604c71f54791d52bebe31', 'name': 'Feng Cheng', 'hidden': False}, {'_id': '678604c71f54791d52bebe32', 'name': 'Lu Qi', 'hidden': False}, {'_id': '678604c71f54791d52bebe33', 'name': 'Liangke Gui', 'hidden': False}, {'_id': '678604c71f54791d52bebe34', 'name': 'Jiepeng Cen', 'hidden': False}, {'_id': '678604c71f54791d52bebe35', 'name': 'Zhibei Ma', 'hidden': False}, {'_id': '678604c71f54791d52bebe36', 'name': 'Alan Yuille', 'hidden': False}, {'_id': '678604c71f54791d52bebe37', 'name': 'Lu Jiang', 'hidden': False}], 'publishedAt': '2025-01-10T18:52:11.000Z', 'title': 'VideoAuteur: Towards Long Narrative Video Generation', 'summary': 'Recent video generation models have shown promising results in producing\\nhigh-quality video clips lasting several seconds. However, these models face\\nchallenges in generating long sequences that convey clear and informative\\nevents, limiting their ability to support coherent narrations. In this paper,\\nwe present a large-scale cooking video dataset designed to advance long-form\\nnarrative generation in the cooking domain. We validate the quality of our\\nproposed dataset in terms of visual fidelity and textual caption accuracy using\\nstate-of-the-art Vision-Language Models (VLMs) and video generation models,\\nrespectively. We further introduce a Long Narrative Video Director to enhance\\nboth visual and semantic coherence in generated videos and emphasize the role\\nof aligning visual embeddings to achieve improved overall video quality. Our\\nmethod demonstrates substantial improvements in generating visually detailed\\nand semantically aligned keyframes, supported by finetuning techniques that\\nintegrate text and image embeddings within the video generation process.\\nProject page: https://videoauteur.github.io/', 'upvotes': 13, 'discussionId': '678604d01f54791d52bec130'}, 'publishedAt': '2025-01-14T01:33:05.846Z', 'title': 'VideoAuteur: Towards Long Narrative Video Generation', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06173.png', 'numComments': 1, 'submittedBy': {'_id': '64b5ba6060274cbb296d6288', 'avatarUrl': '/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg', 'fullname': 'Junfei Xiao', 'name': 'lambertxiao', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.07572', 'authors': [{'_id': '6785df7a934f275b48366bdf', 'user': {'_id': '644a4fbc2166258fccc664bc', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg', 'isPro': False, 'fullname': 'Jialong Wu', 'user': 'callanwu', 'type': 'user'}, 'name': 'Jialong Wu', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-14T08:28:45.818Z', 'hidden': False}, {'_id': '6785df7a934f275b48366be0', 'name': 'Wenbiao Yin', 'hidden': False}, {'_id': '6785df7a934f275b48366be1', 'name': 'Yong Jiang', 'hidden': False}, {'_id': '6785df7a934f275b48366be2', 'user': {'_id': '6643261b8876db14227eeb19', 'avatarUrl': '/avatars/67428c9e37a2273697c0547e1783ec6b.svg', 'isPro': False, 'fullname': 'Zhenglin Wang', 'user': 'wzl0228', 'type': 'user'}, 'name': 'Zhenglin Wang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:08:43.731Z', 'hidden': False}, {'_id': '6785df7a934f275b48366be3', 'user': {'_id': '647229256facfb01d8ae7b89', 'avatarUrl': '/avatars/2fc34d2739b28c1089b20e7a7fa40f0e.svg', 'isPro': False, 'fullname': 'Xi Ze Kun', 'user': 'ZekunXi', 'type': 'user'}, 'name': 'Zekun Xi', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:08:51.642Z', 'hidden': False}, {'_id': '6785df7a934f275b48366be4', 'user': {'_id': '63d32cd7b734eaa4d4fa410b', 'avatarUrl': '/avatars/68acb80f62bc6493e1ad26506999b6c4.svg', 'isPro': False, 'fullname': 'Runnan Fang', 'user': 'Runnaning', 'type': 'user'}, 'name': 'Runnan Fang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:08:58.816Z', 'hidden': False}, {'_id': '6785df7a934f275b48366be5', 'user': {'_id': '64e821f2bddc5b1072b15c2e', 'avatarUrl': '/avatars/618b5a48f2fa62daff4e1922a9aa9e8b.svg', 'isPro': False, 'fullname': 'zhoudeyu', 'user': 'zhoudeyu', 'type': 'user'}, 'name': 'Deyu Zhou', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:09:13.637Z', 'hidden': False}, {'_id': '6785df7a934f275b48366be6', 'user': {'_id': '63a091e42fabbbb89991f5ce', 'avatarUrl': '/avatars/d55485b06461764c36c9edf9d6e8892c.svg', 'isPro': False, 'fullname': 'pengjun xie', 'user': 'xpjandy', 'type': 'user'}, 'name': 'Pengjun Xie', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:09:20.633Z', 'hidden': False}, {'_id': '6785df7a934f275b48366be7', 'user': {'_id': '635b8b6a37c6a2c12e2cce00', 'avatarUrl': '/avatars/229fb72180529141515d1df797b33709.svg', 'isPro': False, 'fullname': 'Fei Huang', 'user': 'hzhwcmhf', 'type': 'user'}, 'name': 'Fei Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:09:29.902Z', 'hidden': False}], 'publishedAt': '2025-01-13T18:58:07.000Z', 'title': 'WebWalker: Benchmarking LLMs in Web Traversal', 'summary': \"Retrieval-augmented generation (RAG) demonstrates remarkable performance\\nacross tasks in open-domain question-answering. However, traditional search\\nengines may retrieve shallow content, limiting the ability of LLMs to handle\\ncomplex, multi-layered information. To address it, we introduce WebWalkerQA, a\\nbenchmark designed to assess the ability of LLMs to perform web traversal. It\\nevaluates the capacity of LLMs to traverse a website's subpages to extract\\nhigh-quality data systematically. We propose WebWalker, which is a multi-agent\\nframework that mimics human-like web navigation through an explore-critic\\nparadigm. Extensive experimental results show that WebWalkerQA is challenging\\nand demonstrates the effectiveness of RAG combined with WebWalker, through the\\nhorizontal and vertical integration in real-world scenarios.\", 'upvotes': 12, 'discussionId': '6785df7c934f275b48366cff'}, 'publishedAt': '2025-01-13T23:49:04.500Z', 'title': 'WebWalker: Benchmarking LLMs in Web Traversal', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07572.png', 'numComments': 2, 'submittedBy': {'_id': '644a4fbc2166258fccc664bc', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg', 'fullname': 'Jialong Wu', 'name': 'callanwu', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 2}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.06458', 'authors': [{'_id': '6785e65a7d58f2945af8034d', 'user': {'_id': '620a0a2e8d5e5dfed284bc41', 'avatarUrl': '/avatars/ca2ddad577227103cdf263a4b7817b22.svg', 'isPro': False, 'fullname': 'huangzhongzhen', 'user': 'zongzi', 'type': 'user'}, 'name': 'Zhongzhen Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:10:03.906Z', 'hidden': False}, {'_id': '6785e65a7d58f2945af8034e', 'name': 'Gui Geng', 'hidden': False}, {'_id': '6785e65a7d58f2945af8034f', 'name': 'Shengyi Hua', 'hidden': False}, {'_id': '6785e65a7d58f2945af80350', 'user': {'_id': '643581a4f3b08e267d990499', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/643581a4f3b08e267d990499/KRhB-48W4IPuB0bX16Ahj.png', 'isPro': False, 'fullname': 'Zhen Huang', 'user': 'ZhenHuang', 'type': 'user'}, 'name': 'Zhen Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:12:15.207Z', 'hidden': False}, {'_id': '6785e65a7d58f2945af80351', 'user': {'_id': '65011b18af1e4021439af578', 'avatarUrl': '/avatars/ae1632c800ceeb43aa223e432f70bc6d.svg', 'isPro': False, 'fullname': 'Haoyang Zou', 'user': 'alanyoung058', 'type': 'user'}, 'name': 'Haoyang Zou', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:12:22.954Z', 'hidden': False}, {'_id': '6785e65a7d58f2945af80352', 'name': 'Shaoting Zhang', 'hidden': False}, {'_id': '6785e65a7d58f2945af80353', 'user': {'_id': '6144a0c4ff1146bbd84d9865', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1661715958139-6144a0c4ff1146bbd84d9865.png', 'isPro': True, 'fullname': 'Pengfei Liu', 'user': 'Pengfei', 'type': 'user'}, 'name': 'Pengfei Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:12:46.582Z', 'hidden': False}, {'_id': '6785e65a7d58f2945af80354', 'name': 'Xiaofan Zhang', 'hidden': False}], 'publishedAt': '2025-01-11T07:10:23.000Z', 'title': 'O1 Replication Journey -- Part 3: Inference-time Scaling for Medical\\n  Reasoning', 'summary': \"Building upon our previous investigations of O1 replication (Part 1: Journey\\nLearning [Qin et al., 2024] and Part 2: Distillation [Huang et al., 2024]),\\nthis work explores the potential of inference-time scaling in large language\\nmodels (LLMs) for medical reasoning tasks, ranging from diagnostic\\ndecision-making to treatment planning. Through extensive experiments on medical\\nbenchmarks of varying complexity (MedQA, Medbullets, and JAMA Clinical\\nChallenges), our investigation reveals several key insights: (1) Increasing\\ninference time does lead to improved performance. With a modest training set of\\n500 samples, our model yields substantial performance improvements of 6%-11%.\\n(2) Task complexity directly correlates with the required length of reasoning\\nchains, confirming the necessity of extended thought processes for challenging\\nproblems. (3) The differential diagnoses generated by our model adhere to the\\nprinciples of the hypothetico-deductive method, producing a list of potential\\nconditions that may explain a patient's symptoms and systematically narrowing\\nthese possibilities by evaluating the evidence. These findings demonstrate the\\npromising synergy between inference-time scaling and journey learning in\\nadvancing LLMs' real-world clinical reasoning capabilities.\", 'upvotes': 12, 'discussionId': '6785e65b7d58f2945af80393'}, 'publishedAt': '2025-01-13T23:22:50.865Z', 'title': 'O1 Replication Journey -- Part 3: Inference-time Scaling for Medical Reasoning', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06458.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5645}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.06842', 'authors': [{'_id': '678646a9195de4bd4d6f75c2', 'user': {'_id': '64cd4743a785f2043b32915e', 'avatarUrl': '/avatars/ba0b497a194dfea8449112d71fc67654.svg', 'isPro': False, 'fullname': 'Tianjin Huang', 'user': 'TianjinHuang', 'type': 'user'}, 'name': 'Tianjin Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T13:11:11.237Z', 'hidden': False}, {'_id': '678646a9195de4bd4d6f75c3', 'name': 'Ziquan Zhu', 'hidden': False}, {'_id': '678646a9195de4bd4d6f75c4', 'name': 'Gaojie Jin', 'hidden': False}, {'_id': '678646a9195de4bd4d6f75c5', 'name': 'Lu Liu', 'hidden': False}, {'_id': '678646a9195de4bd4d6f75c6', 'name': 'Zhangyang Wang', 'hidden': False}, {'_id': '678646a9195de4bd4d6f75c7', 'user': {'_id': '65b04d2291e63920a7898c9e', 'avatarUrl': '/avatars/16360fd939d3d72d47fad5a82981aaa9.svg', 'isPro': False, 'fullname': 'Liu', 'user': 'Shiweiliuiiiiiii', 'type': 'user'}, 'name': 'Shiwei Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T14:53:45.458Z', 'hidden': False}], 'publishedAt': '2025-01-12T15:21:22.000Z', 'title': 'SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training', 'summary': 'Large Language Models (LLMs) have demonstrated exceptional performance across\\ndiverse tasks, yet their training remains highly resource-intensive and\\nsusceptible to critical challenges such as training instability. A predominant\\nsource of this instability stems from gradient and loss spikes, which disrupt\\nthe learning process, often leading to costly interventions like checkpoint\\nrecovery and experiment restarts, further amplifying inefficiencies. This paper\\npresents a comprehensive investigation into gradient spikes observed during LLM\\ntraining, revealing their prevalence across multiple architectures and\\ndatasets. Our analysis shows that these spikes can be up to 1000times larger\\nthan typical gradients, substantially deteriorating model performance. To\\naddress this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a\\nnovel optimizer designed to counteract gradient spikes through momentum reset\\nand spike-aware gradient clipping. Extensive experiments, including both\\npre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam\\nand its variants across various tasks, including (1) LLM pre-training from 60M\\nto 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time\\nSeries Forecasting. Additionally, SPAM facilitates memory-efficient training by\\nenabling sparse momentum, where only a subset of momentum terms are maintained\\nand updated. When operating under memory constraints, SPAM outperforms\\nstate-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our\\nwork underscores the importance of mitigating gradient spikes in LLM training\\nand introduces an effective optimization strategy that enhances both training\\nstability and resource efficiency at scale. Code is available at\\nhttps://github.com/TianjinYellow/SPAM-Optimizer.git', 'upvotes': 7, 'discussionId': '678646ad195de4bd4d6f76eb'}, 'publishedAt': '2025-01-14T06:33:12.265Z', 'title': 'SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06842.png', 'numComments': 1, 'submittedBy': {'_id': '65b04d2291e63920a7898c9e', 'avatarUrl': '/avatars/16360fd939d3d72d47fad5a82981aaa9.svg', 'fullname': 'Liu', 'name': 'Shiweiliuiiiiiii', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.06282', 'authors': [{'_id': '6785e88a6bc168b98ae46a55', 'name': 'Qian Chen', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a56', 'name': 'Yafeng Chen', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a57', 'name': 'Yanni Chen', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a58', 'user': {'_id': '632aa1565f2ff1958c053f9f', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1663738082852-noauth.png', 'isPro': False, 'fullname': 'chenmengzhe', 'user': 'chenmengzhe', 'type': 'user'}, 'name': 'Mengzhe Chen', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:16:32.211Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a59', 'user': {'_id': '6215ca5692c0ecfba9186921', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1645595695434-6215ca5692c0ecfba9186921.png', 'isPro': False, 'fullname': 'Yingda Chen', 'user': 'Yingda', 'type': 'user'}, 'name': 'Yingda Chen', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:16:41.268Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a5a', 'name': 'Chong Deng', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a5b', 'user': {'_id': '64f15d3041425edddeec9410', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/caz_i5eCbGk-B9013DHqb.jpeg', 'isPro': False, 'fullname': 'zhihaodu', 'user': 'zhihaodu', 'type': 'user'}, 'name': 'Zhihao Du', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:16:59.075Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a5c', 'user': {'_id': '6629ed94aabce1b25c3db90c', 'avatarUrl': '/avatars/cbc39db81c8e8f950d3bd2c2e03f71c8.svg', 'isPro': False, 'fullname': 'Ruize Gao', 'user': 'gaoruize', 'type': 'user'}, 'name': 'Ruize Gao', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:17:22.485Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a5d', 'name': 'Changfeng Gao', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a5e', 'user': {'_id': '63d7dcec635499f2163d36b2', 'avatarUrl': '/avatars/1e4afa5807f22025e80af2ebe2ac08d1.svg', 'isPro': False, 'fullname': 'zhifu gao', 'user': 'langgz', 'type': 'user'}, 'name': 'Zhifu Gao', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:17:48.070Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a5f', 'name': 'Yabin Li', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a60', 'name': 'Xiang Lv', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a61', 'user': {'_id': '63f268f8be95ed4c9a9b4948', 'avatarUrl': '/avatars/5e8cee51637c5c66595bb22c0734145e.svg', 'isPro': False, 'fullname': 'Jiaqing Liu', 'user': 'Nick6', 'type': 'user'}, 'name': 'Jiaqing Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:18:16.920Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a62', 'name': 'Haoneng Luo', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a63', 'name': 'Bin Ma', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a64', 'user': {'_id': '64af6a1c7ab7586520eb6f64', 'avatarUrl': '/avatars/8cd025c8e6a1a5ecc94f206bfa90ef65.svg', 'isPro': False, 'fullname': 'Ni', 'user': 'Chongjia', 'type': 'user'}, 'name': 'Chongjia Ni', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:16:04.510Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a65', 'name': 'Xian Shi', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a66', 'user': {'_id': '63281d05ac205d01918b5fc7', 'avatarUrl': '/avatars/fc3e0f7285bb2869a92670f764dfc535.svg', 'isPro': False, 'fullname': 'Jialong Tang', 'user': 'Jialong', 'type': 'user'}, 'name': 'Jialong Tang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:18:50.994Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a67', 'name': 'Hui Wang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a68', 'name': 'Hao Wang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a69', 'name': 'Wen Wang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a6a', 'user': {'_id': '60b9e6837946aff342f734ae', 'avatarUrl': '/avatars/a711a6aa35757dfd7b78b26098a964fc.svg', 'isPro': False, 'fullname': 'Yuxuan Wang', 'user': 'ColorfulAI', 'type': 'user'}, 'name': 'Yuxuan Wang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:23:36.507Z', 'hidden': True}, {'_id': '6785e88a6bc168b98ae46a6b', 'name': 'Yunlan Xu', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a6c', 'name': 'Fan Yu', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a6d', 'name': 'Zhijie Yan', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a6e', 'name': 'Yexin Yang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a6f', 'user': {'_id': '64b0a77df12b47366663884c', 'avatarUrl': '/avatars/a212ea862abb5966060e439dd0e7656f.svg', 'isPro': False, 'fullname': 'Baosong Yang', 'user': 'Baosong', 'type': 'user'}, 'name': 'Baosong Yang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:24:22.882Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a70', 'name': 'Xian Yang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a71', 'name': 'Guanrou Yang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a72', 'name': 'Tianyu Zhao', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a73', 'name': 'Qinglin Zhang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a74', 'user': {'_id': '632493f2a099f5a84cee66d9', 'avatarUrl': '/avatars/6c0ca937e35d2ef32eed6b99bd1d7313.svg', 'isPro': False, 'fullname': 'Zhang', 'user': 'shiliang', 'type': 'user'}, 'name': 'Shiliang Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:25:14.833Z', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a75', 'name': 'Nan Zhao', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a76', 'name': 'Pei Zhang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a77', 'name': 'Chong Zhang', 'hidden': False}, {'_id': '6785e88a6bc168b98ae46a78', 'name': 'Jinren Zhou', 'hidden': False}], 'publishedAt': '2025-01-10T15:55:27.000Z', 'title': 'MinMo: A Multimodal Large Language Model for Seamless Voice Interaction', 'summary': 'Recent advancements in large language models (LLMs) and multimodal\\nspeech-text models have laid the groundwork for seamless voice interactions,\\nenabling real-time, natural, and human-like conversations. Previous models for\\nvoice interactions are categorized as native and aligned. Native models\\nintegrate speech and text processing in one framework but struggle with issues\\nlike differing sequence lengths and insufficient pre-training. Aligned models\\nmaintain text LLM capabilities but are often limited by small datasets and a\\nnarrow focus on speech tasks. In this work, we introduce MinMo, a Multimodal\\nLarge Language Model with approximately 8B parameters for seamless voice\\ninteraction. We address the main limitations of prior aligned multimodal\\nmodels. We train MinMo through multiple stages of speech-to-text alignment,\\ntext-to-speech alignment, speech-to-speech alignment, and duplex interaction\\nalignment, on 1.4 million hours of diverse speech data and a broad range of\\nspeech tasks. After the multi-stage training, MinMo achieves state-of-the-art\\nperformance across various benchmarks for voice comprehension and generation\\nwhile maintaining the capabilities of text LLMs, and also facilitates\\nfull-duplex conversation, that is, simultaneous two-way communication between\\nthe user and the system. Moreover, we propose a novel and simple voice decoder\\nthat outperforms prior models in voice generation. The enhanced\\ninstruction-following capabilities of MinMo supports controlling speech\\ngeneration based on user instructions, with various nuances including emotions,\\ndialects, and speaking rates, and mimicking specific voices. For MinMo, the\\nspeech-to-text latency is approximately 100ms, full-duplex latency is\\napproximately 600ms in theory and 800ms in practice. The MinMo project web page\\nis https://funaudiollm.github.io/minmo, and the code and models will be\\nreleased soon.', 'upvotes': 7, 'discussionId': '6785e88c6bc168b98ae46b59'}, 'publishedAt': '2025-01-13T23:31:20.641Z', 'title': 'MinMo: A Multimodal Large Language Model for Seamless Voice Interaction', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06282.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5645}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.07171', 'authors': [{'_id': '678603c0c054524aa22be7e1', 'user': {'_id': '643c3fb526f177a3e4181e05', 'avatarUrl': '/avatars/4f08ca15c5fbd2f8bb3d5c24f3fcc7b8.svg', 'isPro': False, 'fullname': 'Alejandro Lozano', 'user': 'lozanoe', 'type': 'user'}, 'name': 'Alejandro Lozano', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-01-14T06:27:14.763Z', 'hidden': False}, {'_id': '678603c0c054524aa22be7e2', 'user': {'_id': '65ac61120844d9e0d67a9f89', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/65ac61120844d9e0d67a9f89/OzA_yxFoeuyhmc3xdYYdP.jpeg', 'isPro': False, 'fullname': 'Min Woo Sun', 'user': 'minwoosun', 'type': 'user'}, 'name': 'Min Woo Sun', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-14T06:45:53.756Z', 'hidden': False}, {'_id': '678603c0c054524aa22be7e3', 'name': 'James Burgess', 'hidden': False}, {'_id': '678603c0c054524aa22be7e4', 'name': 'Liangyu Chen', 'hidden': False}, {'_id': '678603c0c054524aa22be7e5', 'user': {'_id': '6500e67e13f1546526bd373a', 'avatarUrl': '/avatars/80ef1ce58e93b773dcbcc2d5b53175c2.svg', 'isPro': True, 'fullname': 'Jeff Nirschl', 'user': 'jnirschl', 'type': 'user'}, 'name': 'Jeffrey J Nirschl', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-01-14T06:27:14.763Z', 'hidden': False}, {'_id': '678603c0c054524aa22be7e6', 'name': 'Jeffrey Gu', 'hidden': False}, {'_id': '678603c0c054524aa22be7e7', 'name': 'Ivan Lopez', 'hidden': False}, {'_id': '678603c0c054524aa22be7e8', 'name': 'Josiah Aklilu', 'hidden': False}, {'_id': '678603c0c054524aa22be7e9', 'name': 'Austin Wolfgang Katzer', 'hidden': False}, {'_id': '678603c0c054524aa22be7ea', 'name': 'Collin Chiu', 'hidden': False}, {'_id': '678603c0c054524aa22be7eb', 'name': 'Anita Rau', 'hidden': False}, {'_id': '678603c0c054524aa22be7ec', 'name': 'Xiaohan Wang', 'hidden': False}, {'_id': '678603c0c054524aa22be7ed', 'user': {'_id': '62da55164398e21bf7f0e292', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62da55164398e21bf7f0e292/xjKkG8IA2IZZqCdjApSh3.jpeg', 'isPro': False, 'fullname': 'Yuhui Zhang', 'user': 'yuhuizhang', 'type': 'user'}, 'name': 'Yuhui Zhang', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-14T06:28:22.730Z', 'hidden': False}, {'_id': '678603c0c054524aa22be7ee', 'name': 'Alfred Seunghoon Song', 'hidden': False}, {'_id': '678603c0c054524aa22be7ef', 'name': 'Robert Tibshirani', 'hidden': False}, {'_id': '678603c0c054524aa22be7f0', 'user': {'_id': '677c8b2e92550a07fcad0f50', 'avatarUrl': '/avatars/2be26e8f25e98cfe5b1d227ee0409cd0.svg', 'isPro': False, 'fullname': 'Serena Yeung-Levy', 'user': 'yeunglevy', 'type': 'user'}, 'name': 'Serena Yeung-Levy', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-01-14T06:27:14.763Z', 'hidden': False}], 'publishedAt': '2025-01-13T09:58:03.000Z', 'title': 'BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and\\n  Vision-Language Models Derived from Scientific Literature', 'summary': 'The development of vision-language models (VLMs) is driven by large-scale and\\ndiverse multimodal datasets. However, progress toward generalist biomedical\\nVLMs is limited by the lack of annotated, publicly accessible datasets across\\nbiology and medicine. Existing efforts are restricted to narrow domains,\\nmissing the full diversity of biomedical knowledge encoded in scientific\\nliterature. To address this gap, we introduce BIOMEDICA, a scalable,\\nopen-source framework to extract, annotate, and serialize the entirety of the\\nPubMed Central Open Access subset into an easy-to-use, publicly accessible\\ndataset.Our framework produces a comprehensive archive with over 24 million\\nunique image-text pairs from over 6 million articles. Metadata and\\nexpert-guided annotations are also provided. We demonstrate the utility and\\naccessibility of our resource by releasing BMCA-CLIP, a suite of CLIP-style\\nmodels continuously pre-trained on the BIOMEDICA dataset via streaming,\\neliminating the need to download 27 TB of data locally.On average, our models\\nachieve state-of-the-art performance across 40 tasks - spanning pathology,\\nradiology, ophthalmology, dermatology, surgery, molecular biology,\\nparasitology, and cell biology - excelling in zero-shot classification with a\\n6.56% average improvement (as high as 29.8% and 17.5% in dermatology and\\nophthalmology, respectively), and stronger image-text retrieval, all while\\nusing 10x less compute. To foster reproducibility and collaboration, we release\\nour codebase and dataset for the broader research community.', 'upvotes': 2, 'discussionId': '678603c2c054524aa22be8d5'}, 'publishedAt': '2025-01-14T04:52:18.497Z', 'title': 'BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and Vision-Language Models Derived from Scientific Literature', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07171.png', 'numComments': 1, 'submittedBy': {'_id': '60107b385ac3e86b3ea4fc34', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg', 'fullname': 'Daniel van Strien', 'name': 'davanstrien', 'type': 'user', 'isPro': True, 'isHf': True, 'isMod': False, 'followerCount': 491}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.06590', 'authors': [{'_id': '6785e9ade1226951bc8c83cb', 'user': {'_id': '63357c608adfa81faf2ac180', 'avatarUrl': '/avatars/ae0314c644f882251baf59b9134fd36f.svg', 'isPro': False, 'fullname': 'Xiangru Tang', 'user': 'RTT1', 'type': 'user'}, 'name': 'Xiangru Tang', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-01-14T04:35:59.001Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83cc', 'user': {'_id': '64915cd1129c5fe554d8a54e', 'avatarUrl': '/avatars/ea367103ddb2bfbda0cb05a9e4ca4862.svg', 'isPro': False, 'fullname': 'TianYu Hu', 'user': 'CamelH', 'type': 'user'}, 'name': 'Tianyu Hu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:25:53.078Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83cd', 'name': 'Muyang Ye', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83ce', 'user': {'_id': '62970df979f193515da13dc0', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62970df979f193515da13dc0/A-mgKIcgTXRJ54GCHswTq.jpeg', 'isPro': False, 'fullname': 'Yanjun Shao', 'user': 'super-dainiu', 'type': 'user'}, 'name': 'Yanjun Shao', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:26:07.193Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83cf', 'name': 'Xunjian Yin', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83d0', 'user': {'_id': '64bb4eeb5ee4641b32d7db27', 'avatarUrl': '/avatars/fe32fe5e5f2914b46f1d05d1a67d4314.svg', 'isPro': False, 'fullname': 'Siru Ouyang', 'user': 'siruo2', 'type': 'user'}, 'name': 'Siru Ouyang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:44:50.034Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83d1', 'user': {'_id': '628c8598ef14f971b698107f', 'avatarUrl': '/avatars/3a4ad87e6b5f9e836a1160d869df1447.svg', 'isPro': False, 'fullname': 'Zhou', 'user': 'Wangchunshu', 'type': 'user'}, 'name': 'Wangchunshu Zhou', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:47:31.168Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83d2', 'user': {'_id': '60f5f68fa7fd83d025749234', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/60f5f68fa7fd83d025749234/gCeJAZfzaANAcEvI6v5-P.jpeg', 'isPro': False, 'fullname': 'Pan Lu', 'user': 'lupantech', 'type': 'user'}, 'name': 'Pan Lu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:47:40.737Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83d3', 'user': {'_id': '5f82f9f7f0801648bf8844b2', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1669627733134-5f82f9f7f0801648bf8844b2.jpeg', 'isPro': False, 'fullname': 'Zhuosheng Zhang', 'user': 'cooelf', 'type': 'user'}, 'name': 'Zhuosheng Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:47:46.326Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83d4', 'user': {'_id': '62f662bcc58915315c4eccea', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg', 'isPro': True, 'fullname': 'Yilun', 'user': 'yilunzhao', 'type': 'user'}, 'name': 'Yilun Zhao', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:48:02.426Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83d5', 'user': {'_id': '5f5ba21188f57f65f951f255', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1599840760465-noauth.png', 'isPro': False, 'fullname': 'Arman Cohan', 'user': 'armanc', 'type': 'user'}, 'name': 'Arman Cohan', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:48:08.442Z', 'hidden': False}, {'_id': '6785e9ade1226951bc8c83d6', 'name': 'Mark Gerstein', 'hidden': False}], 'publishedAt': '2025-01-11T17:10:30.000Z', 'title': 'ChemAgent: Self-updating Library in Large Language Models Improves\\n  Chemical Reasoning', 'summary': 'Chemical reasoning usually involves complex, multi-step processes that demand\\nprecise calculations, where even minor errors can lead to cascading failures.\\nFurthermore, large language models (LLMs) encounter difficulties handling\\ndomain-specific formulas, executing reasoning steps accurately, and integrating\\ncode effectively when tackling chemical reasoning tasks. To address these\\nchallenges, we present ChemAgent, a novel framework designed to improve the\\nperformance of LLMs through a dynamic, self-updating library. This library is\\ndeveloped by decomposing chemical tasks into sub-tasks and compiling these\\nsub-tasks into a structured collection that can be referenced for future\\nqueries. Then, when presented with a new problem, ChemAgent retrieves and\\nrefines pertinent information from the library, which we call memory,\\nfacilitating effective task decomposition and the generation of solutions. Our\\nmethod designs three types of memory and a library-enhanced reasoning\\ncomponent, enabling LLMs to improve over time through experience. Experimental\\nresults on four chemical reasoning datasets from SciBench demonstrate that\\nChemAgent achieves performance gains of up to 46% (GPT-4), significantly\\noutperforming existing methods. Our findings suggest substantial potential for\\nfuture applications, including tasks such as drug discovery and materials\\nscience. Our code can be found at https://github.com/gersteinlab/chemagent', 'upvotes': 2, 'discussionId': '6785e9afe1226951bc8c8468'}, 'publishedAt': '2025-01-13T23:36:33.019Z', 'title': 'ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06590.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5645}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.07574', 'authors': [{'_id': '6785e58ffea9f9a51055f21b', 'user': {'_id': '63f77c1edf66696652f167b7', 'avatarUrl': '/avatars/d19cd3650a662051eaa7abbc80fd7a4f.svg', 'isPro': False, 'fullname': 'Xingchen Liu', 'user': 'wenchang05', 'type': 'user'}, 'name': 'Xingchen Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:48:41.956Z', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f21c', 'name': 'Piyush Tayal', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f21d', 'user': {'_id': '649bf403fd9cea8366d669ad', 'avatarUrl': '/avatars/27bd8ca9a948ec38fee950b64f669ce3.svg', 'isPro': False, 'fullname': 'Jianyuan Wang', 'user': 'JianyuanWang', 'type': 'user'}, 'name': 'Jianyuan Wang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:48:59.566Z', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f21e', 'user': {'_id': '66e844b28b2ed9cd2649285c', 'avatarUrl': '/avatars/adb3f428225627c77153f917777a8231.svg', 'isPro': False, 'fullname': 'Jesus Zarzar', 'user': 'zarzarj', 'type': 'user'}, 'name': 'Jesus Zarzar', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:49:05.230Z', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f21f', 'name': 'Tom Monnier', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f220', 'name': 'Konstantinos Tertikas', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f221', 'user': {'_id': '61feaf91fe53002dadb25586', 'avatarUrl': '/avatars/f84ff3fb8f8e78e2cb636f4673c91ddc.svg', 'isPro': False, 'fullname': 'Duan', 'user': 'Jiali', 'type': 'user'}, 'name': 'Jiali Duan', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:49:24.788Z', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f222', 'name': 'Antoine Toisoul', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f223', 'name': 'Jason Y. Zhang', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f224', 'name': 'Natalia Neverova', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f225', 'name': 'Andrea Vedaldi', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f226', 'user': {'_id': '63e6d41db6a40bf941e4980c', 'avatarUrl': '/avatars/1483f177c9ed6bbe96cbce5a1fa98ceb.svg', 'isPro': False, 'fullname': 'Roman Shapovalov', 'user': 'EarlGr', 'type': 'user'}, 'name': 'Roman Shapovalov', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-14T09:51:06.525Z', 'hidden': False}, {'_id': '6785e58ffea9f9a51055f227', 'name': 'David Novotny', 'hidden': False}], 'publishedAt': '2025-01-13T18:59:20.000Z', 'title': 'UnCommon Objects in 3D', 'summary': 'We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for\\n3D deep learning and 3D generative AI. uCO3D is the largest publicly-available\\ncollection of high-resolution videos of objects with 3D annotations that\\nensures full-360^{circ} coverage. uCO3D is significantly more diverse than\\nMVImgNet and CO3Dv2, covering more than 1,000 object categories. It is also of\\nhigher quality, due to extensive quality checks of both the collected videos\\nand the 3D annotations. Similar to analogous datasets, uCO3D contains\\nannotations for 3D camera poses, depth maps and sparse point clouds. In\\naddition, each object is equipped with a caption and a 3D Gaussian Splat\\nreconstruction. We train several large 3D models on MVImgNet, CO3Dv2, and uCO3D\\nand obtain superior results using the latter, showing that uCO3D is better for\\nlearning applications.', 'upvotes': 2, 'discussionId': '6785e593fea9f9a51055f3af'}, 'publishedAt': '2025-01-13T23:18:37.890Z', 'title': 'UnCommon Objects in 3D', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07574.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5645}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.06708', 'authors': [{'_id': '6786749192a268ed83174bfd', 'name': 'Tzu-Heng Huang', 'hidden': False}, {'_id': '6786749192a268ed83174bfe', 'user': {'_id': '659590c8994d0ef581417913', 'avatarUrl': '/avatars/cef10191f915a99583a69e9e0ac8a330.svg', 'isPro': False, 'fullname': 'Manjot Bilkhu', 'user': 'mbilkhu', 'type': 'user'}, 'name': 'Manjot Bilkhu', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-14T14:45:33.269Z', 'hidden': False}, {'_id': '6786749192a268ed83174bff', 'name': 'Frederic Sala', 'hidden': False}, {'_id': '6786749192a268ed83174c00', 'name': 'Javier Movellan', 'hidden': False}], 'publishedAt': '2025-01-12T04:28:14.000Z', 'title': 'Evaluating Sample Utility for Data Selection by Mimicking Model Weights', 'summary': \"Foundation models rely on large-scale web-crawled datasets, which frequently\\ncontain noisy data, biases, and irrelevant content. Existing data selection\\ntechniques typically use human heuristics, downstream evaluation datasets, or\\nspecialized scoring models, and can overlook samples' utility in the training\\nprocess. Instead, we propose a new approach, Mimic Score, a data quality metric\\nthat uses a pretrained reference model as a guide to assess the usefulness of\\ndata samples for training a new model. It relies on the alignment between the\\ngradient of the new model parameters and the vector pointing toward the\\nreference model in weight space. Samples that misalign with this direction are\\nconsidered low-value and can be filtered out. Motivated by the Mimic score, we\\ndevelop Grad-Mimic, a data selection framework that identifies and prioritizes\\nuseful samples, automating the selection process to create effective filters.\\nEmpirically, using Mimic scores to guide model training results in consistent\\nperformance gains across six image datasets and enhances the performance of\\nCLIP models. Moreover, Mimic scores and their associated filters improve upon\\nexisting filtering methods and offer accurate estimation of dataset quality.\", 'upvotes': 0, 'discussionId': '6786749292a268ed83174c42'}, 'publishedAt': '2025-01-14T09:41:28.476Z', 'title': 'Evaluating Sample Utility for Data Selection by Mimicking Model Weights', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06708.png', 'numComments': 1, 'submittedBy': {'_id': '659590c8994d0ef581417913', 'avatarUrl': '/avatars/cef10191f915a99583a69e9e0ac8a330.svg', 'fullname': 'Manjot Bilkhu', 'name': 'mbilkhu', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 2}, 'isAuthorParticipating': True}"
]