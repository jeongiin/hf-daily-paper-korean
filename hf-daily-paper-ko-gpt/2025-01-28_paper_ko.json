[
    {
        "paper": {
            "id": "2501.15368",
            "authors": [
                {
                    "_id": "67986c6822990ae89bb71fb9",
                    "user": {
                        "_id": "6797cc0ff386b10d1609e3ff",
                        "avatarUrl": "/avatars/3ec1020e974ed01f60a46150501171da.svg",
                        "isPro": false,
                        "fullname": "Yadong Li",
                        "user": "AdamLee1",
                        "type": "user"
                    },
                    "name": "Yadong Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T10:29:02.659Z",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fba",
                    "name": "Jun Liu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fbb",
                    "name": "Tao Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fbc",
                    "name": "Tao Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fbd",
                    "name": "Song Chen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fbe",
                    "name": "Tianpeng Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fbf",
                    "name": "Zehuan Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc0",
                    "name": "Lijun Liu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc1",
                    "name": "Lingfeng Ming",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc2",
                    "name": "Guosheng Dong",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc3",
                    "name": "Da Pan",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc4",
                    "name": "Chong Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc5",
                    "name": "Yuanbo Fang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc6",
                    "name": "Dongdong Kuang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc7",
                    "user": {
                        "_id": "65e88bfa7b458aa68925ea89",
                        "avatarUrl": "/avatars/6cfd5c3fceda7d3f2cb52639fc6b1597.svg",
                        "isPro": false,
                        "fullname": "Wang Ming Rui",
                        "user": "reiiichan",
                        "type": "user"
                    },
                    "name": "Mingrui Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:55:18.208Z",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc8",
                    "name": "Chenglin Zhu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fc9",
                    "name": "Youwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fca",
                    "name": "Hongyu Guo",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fcb",
                    "name": "Fengyu Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fcc",
                    "user": {
                        "_id": "65e71ef39cf349af2940b317",
                        "avatarUrl": "/avatars/fc1cd8d3510946fc947d67b16b51834b.svg",
                        "isPro": false,
                        "fullname": "Yuran Wang",
                        "user": "Ryann829",
                        "type": "user"
                    },
                    "name": "Yuran Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-28T13:52:53.610Z",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fcd",
                    "name": "Bowen Ding",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fce",
                    "name": "Wei Song",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fcf",
                    "name": "Xu Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd0",
                    "name": "Yuqi Huo",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd1",
                    "name": "Zheng Liang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd2",
                    "name": "Shusen Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd3",
                    "name": "Xin Wu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd4",
                    "name": "Shuai Zhao",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd5",
                    "name": "Linchu Xiong",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd6",
                    "name": "Yozhen Wu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd7",
                    "name": "Jiahui Ye",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd8",
                    "name": "Wenhao Lu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fd9",
                    "name": "Bowen Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fda",
                    "name": "Yan Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fdb",
                    "name": "Yaqi Zhou",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fdc",
                    "name": "Xin Chen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fdd",
                    "name": "Lei Su",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fde",
                    "name": "Hongda Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fdf",
                    "name": "Fuzhong Chen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe0",
                    "name": "Xuezhen Dong",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe1",
                    "name": "Na Nie",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe2",
                    "name": "Zhiying Wu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe3",
                    "name": "Bin Xiao",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe4",
                    "name": "Ting Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe5",
                    "name": "Shunya Dang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe6",
                    "name": "Ping Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe7",
                    "name": "Yijia Sun",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe8",
                    "name": "Jincheng Wu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fe9",
                    "name": "Jinjie Yang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fea",
                    "name": "Xionghai Lin",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71feb",
                    "name": "Zhi Ma",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fec",
                    "name": "Kegeng Wu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fed",
                    "name": "Jia li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fee",
                    "name": "Aiyuan Yang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fef",
                    "name": "Hui Liu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff0",
                    "name": "Jianqiang Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff1",
                    "name": "Xiaoxi Chen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff2",
                    "name": "Guangwei Ai",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff3",
                    "name": "Wentao Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff4",
                    "name": "Yicong Chen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff5",
                    "name": "Xiaoqin Huang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff6",
                    "name": "Kun Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff7",
                    "name": "Wenjing Luo",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff8",
                    "name": "Yifei Duan",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ff9",
                    "name": "Lingling Zhu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ffa",
                    "name": "Ran Xiao",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ffb",
                    "name": "Zhe Su",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ffc",
                    "name": "Jiani Pu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ffd",
                    "name": "Dian Wang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71ffe",
                    "name": "Xu Jia",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb71fff",
                    "name": "Tianyu Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72000",
                    "name": "Mengyu Ai",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72001",
                    "name": "Mang Wang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72002",
                    "name": "Yujing Qiao",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72003",
                    "name": "Lei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72004",
                    "name": "Yanjun Shen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72005",
                    "name": "Fan Yang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72006",
                    "name": "Miao Zhen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72007",
                    "name": "Yijie Zhou",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72008",
                    "name": "Mingyang Chen",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72009",
                    "name": "Fei Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb7200a",
                    "name": "Chenzheng Zhu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb7200b",
                    "name": "Keer Lu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb7200c",
                    "name": "Yaqi Zhao",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb7200d",
                    "name": "Hao Liang",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb7200e",
                    "name": "Youquan Li",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb7200f",
                    "name": "Yanzhao Qin",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72010",
                    "name": "Linzhuang Sun",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72011",
                    "name": "Jianhua Xu",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72012",
                    "name": "Haoze Sun",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72013",
                    "name": "Mingan Lin",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72014",
                    "name": "Zenan Zhou",
                    "hidden": false
                },
                {
                    "_id": "67986c6822990ae89bb72015",
                    "user": {
                        "_id": "6501587887b370a56ad2608e",
                        "avatarUrl": "/avatars/6779baaa8ed9032de55a2f78e1f52e20.svg",
                        "isPro": false,
                        "fullname": "Wei-Peng Chen",
                        "user": "whenfra",
                        "type": "user"
                    },
                    "name": "Weipeng Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:54:48.451Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-26T02:19:03.000Z",
            "title": "Baichuan-Omni-1.5 Technical Report",
            "summary": "We introduce Baichuan-Omni-1.5, an omni-modal model that not only has\nomni-modal understanding capabilities but also provides end-to-end audio\ngeneration capabilities. To achieve fluent and high-quality interaction across\nmodalities without compromising the capabilities of any modality, we\nprioritized optimizing three key aspects. First, we establish a comprehensive\ndata cleaning and synthesis pipeline for multimodal data, obtaining about 500B\nhigh-quality data (text, audio, and vision). Second, an audio-tokenizer\n(Baichuan-Audio-Tokenizer) has been designed to capture both semantic and\nacoustic information from audio, enabling seamless integration and enhanced\ncompatibility with MLLM. Lastly, we designed a multi-stage training strategy\nthat progressively integrates multimodal alignment and multitask fine-tuning,\nensuring effective synergy across all modalities. Baichuan-Omni-1.5 leads\ncontemporary models (including GPT4o-mini and MiniCPM-o 2.6) in terms of\ncomprehensive omni-modal capabilities. Notably, it achieves results comparable\nto leading models such as Qwen2-VL-72B across various multimodal medical\nbenchmarks.",
            "upvotes": 28,
            "discussionId": "67986c6b22990ae89bb720aa"
        },
        "translation_title": "Baichuan-Omni-1.5 기술 보고서",
        "purpose": "오미모달 모델의 이해 능력과 오디오 생성 능력을 결합하여 다양한 매체 간의 원활한 상호작용을 제공하는 것",
        "method": [
            "약 500B의 고품질 데이터를 확보하기 위해 멀티모달 데이터에 대한 포괄적인 데이터 정리 및 합성 파이프라인을 구축함(First, we establish a comprehensive data cleaning and synthesis pipeline for multimodal data, obtaining about 500B high-quality data (text, audio, and vision).)",
            "의미 정보와 음향 정보를 모두 포착하는 오디오 토크나이저를 설계하여 MLLM과의 통합 가능성을 높임(Second, an audio-tokenizer (Baichuan-Audio-Tokenizer) has been designed to capture both semantic and acoustic information from audio, enabling seamless integration and enhanced compatibility with MLLM.)",
            "다단계 훈련 전략을 설계하여 멀티모달 정렬과 다중 작업 세분화를 점진적으로 통합함(Lastly, we designed a multi-stage training strategy that progressively integrates multimodal alignment and multitask fine-tuning, ensuring effective synergy across all modalities.)"
        ],
        "conclusion": "Baichuan-Omni-1.5는 현대 모델들보다 경쟁력 있는 오미모달 능력을 보여주며, 다양한 멀티모달 의료 벤치마크에서 선도 모델에 비견되는 성과를 달성함.",
        "keywords": [
            "Multimodal Learning",
            "Audio Generation",
            "Large Language Models"
        ]
    },
    {
        "paper": {
            "id": "2501.15383",
            "authors": [
                {
                    "_id": "67986c83b5e71350993d28eb",
                    "name": "An Yang",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28ec",
                    "user": {
                        "_id": "6583ab7983a9e1460c67d876",
                        "avatarUrl": "/avatars/74400bc448c3f07e23a4cd53d68a6af7.svg",
                        "isPro": false,
                        "fullname": "bowen",
                        "user": "bowenYu",
                        "type": "user"
                    },
                    "name": "Bowen Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:56:10.598Z",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28ed",
                    "name": "Chengyuan Li",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28ee",
                    "user": {
                        "_id": "6434d4989bd5a84b5dd0b0f5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg",
                        "isPro": false,
                        "fullname": "Dayiheng Liu",
                        "user": "Losin94",
                        "type": "user"
                    },
                    "name": "Dayiheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:56:44.491Z",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28ef",
                    "name": "Fei Huang",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f0",
                    "name": "Haoyan Huang",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f1",
                    "name": "Jiandong Jiang",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f2",
                    "user": {
                        "_id": "654bead777401b47e6424f88",
                        "avatarUrl": "/avatars/7bcbdbb051c93b004f0dc3ad36c4a0ce.svg",
                        "isPro": false,
                        "fullname": "Jianhong Tu",
                        "user": "ToviTu",
                        "type": "user"
                    },
                    "name": "Jianhong Tu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:58:35.581Z",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f3",
                    "name": "Jianwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f4",
                    "name": "Jingren Zhou",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f5",
                    "user": {
                        "_id": "620760a26e3b7210c2ff1943",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
                        "isPro": false,
                        "fullname": "Junyang Lin",
                        "user": "JustinLin610",
                        "type": "user"
                    },
                    "name": "Junyang Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:57:31.261Z",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f6",
                    "name": "Kai Dang",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f7",
                    "user": {
                        "_id": "65b0b3957e5d5a4ecc750de0",
                        "avatarUrl": "/avatars/e0d79d3265ca4ad5c5411feb01043fb4.svg",
                        "isPro": false,
                        "fullname": "Kexin Yang",
                        "user": "dawn0929",
                        "type": "user"
                    },
                    "name": "Kexin Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:57:56.435Z",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f8",
                    "name": "Le Yu",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28f9",
                    "name": "Mei Li",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28fa",
                    "user": {
                        "_id": "636a390037d9329b4a007009",
                        "avatarUrl": "/avatars/a3c9117e104d4667e39e20ec83dc5cd6.svg",
                        "isPro": false,
                        "fullname": "Minmin Sun",
                        "user": "minminsun",
                        "type": "user"
                    },
                    "name": "Minmin Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:58:27.795Z",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28fb",
                    "name": "Qin Zhu",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28fc",
                    "name": "Rui Men",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28fd",
                    "name": "Tao He",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28fe",
                    "name": "Weijia Xu",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d28ff",
                    "name": "Wenbiao Yin",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d2900",
                    "user": {
                        "_id": "63f4c99721eb234ab73dd112",
                        "avatarUrl": "/avatars/162e92d7aeb7de1c6ebf4d6e2bff33f5.svg",
                        "isPro": false,
                        "fullname": "yu wenyuan",
                        "user": "liuxinyijian",
                        "type": "user"
                    },
                    "name": "Wenyuan Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T13:58:11.021Z",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d2901",
                    "name": "Xiafei Qiu",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d2902",
                    "name": "Xingzhang Ren",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d2903",
                    "name": "Xinlong Yang",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d2904",
                    "name": "Yong Li",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d2905",
                    "name": "Zhiying Xu",
                    "hidden": false
                },
                {
                    "_id": "67986c83b5e71350993d2906",
                    "name": "Zipeng Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-26T03:47:25.000Z",
            "title": "Qwen2.5-1M Technical Report",
            "summary": "We introduce Qwen2.5-1M, a series of models that extend the context length to\n1 million tokens. Compared to the previous 128K version, the Qwen2.5-1M series\nhave significantly enhanced long-context capabilities through long-context\npre-training and post-training. Key techniques such as long data synthesis,\nprogressive pre-training, and multi-stage supervised fine-tuning are employed\nto effectively enhance long-context performance while reducing training costs.\n  To promote the use of long-context models among a broader user base, we\npresent and open-source our inference framework. This framework includes a\nlength extrapolation method that can expand the model context lengths by at\nleast four times, or even more, without additional training. To reduce\ninference costs, we implement a sparse attention method along with chunked\nprefill optimization for deployment scenarios and a sparsity refinement method\nto improve precision. Additionally, we detail our optimizations in the\ninference engine, including kernel optimization, pipeline parallelism, and\nscheduling optimization, which significantly enhance overall inference\nperformance. By leveraging our inference framework, the Qwen2.5-1M models\nachieve a remarkable 3x to 7x prefill speedup in scenarios with 1 million\ntokens of context. This framework provides an efficient and powerful solution\nfor developing applications that require long-context processing using\nopen-source models.\n  The Qwen2.5-1M series currently includes the open-source models\nQwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M, as well as the API-accessed\nmodel Qwen2.5-Turbo. Evaluations show that Qwen2.5-1M models have been greatly\nimproved in long-context tasks without compromising performance in\nshort-context scenarios. Specifically, the Qwen2.5-14B-Instruct-1M model\nsignificantly outperforms GPT-4o-mini in long-context tasks and supports\ncontexts eight times longer.",
            "upvotes": 15,
            "discussionId": "67986c84b5e71350993d2974"
        },
        "translation_title": "Qwen2.5-1M 기술 보고서",
        "purpose": "1백만 토큰의 긴 맥락을 지원하는 모델 시리즈의 개발과 긴 맥락 성능 개선",
        "method": [
            "긴 맥락 훈련 및 후속 훈련을 통해 긴 맥락 성능을 놀랍도록 향상시킴(Compared to the previous 128K version, the Qwen2.5-1M series have significantly enhanced long-context capabilities through long-context pre-training and post-training.)",
            "모델 맥락 길이를 최소 네 배 확장할 수 있는 길이 외삽 방법을 제시하고 오픈소스화 함(To promote the use of long-context models among a broader user base, we present and open-source our inference framework.)",
            "스파스 어텐션 방법과 청크 prefill 최적화를 구현하여 추론 비용 절감 및 성능 개선 수행(Additionally, we detail our optimizations in the inference engine, including kernel optimization, pipeline parallelism, and scheduling optimization, which significantly enhance overall inference performance.)"
        ],
        "conclusion": "Qwen2.5-1M 모델은 1백만 토큰의 맥락에서도 3배에서 7배의 prefill 속도 향상을 이룩하였으며, 긴 맥락 작업에서도 성능을 개선하면서 짧은 맥락에서의 성능은 유지됨.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2501.16142",
            "authors": [
                {
                    "_id": "67986cbc7dbf69e4e38539b7",
                    "name": "Scott Fujimoto",
                    "hidden": false
                },
                {
                    "_id": "67986cbc7dbf69e4e38539b8",
                    "user": {
                        "_id": "64b6df54dce8f1fbb8ac9ed7",
                        "avatarUrl": "/avatars/82ca21cb9c8bacde071769bf4a888375.svg",
                        "isPro": false,
                        "fullname": "Pierluca D'Oro",
                        "user": "pierluca",
                        "type": "user"
                    },
                    "name": "Pierluca D'Oro",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:09:37.496Z",
                    "hidden": false
                },
                {
                    "_id": "67986cbc7dbf69e4e38539b9",
                    "name": "Amy Zhang",
                    "hidden": false
                },
                {
                    "_id": "67986cbc7dbf69e4e38539ba",
                    "user": {
                        "_id": "6344cf73ee1504dbcd5bdfe7",
                        "avatarUrl": "/avatars/6dd2bf1f9c5679e5c8c85d62c9836aac.svg",
                        "isPro": false,
                        "fullname": "Yuandong Tian",
                        "user": "tydsh",
                        "type": "user"
                    },
                    "name": "Yuandong Tian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:10:10.676Z",
                    "hidden": false
                },
                {
                    "_id": "67986cbc7dbf69e4e38539bb",
                    "name": "Michael Rabbat",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-27T15:36:37.000Z",
            "title": "Towards General-Purpose Model-Free Reinforcement Learning",
            "summary": "Reinforcement learning (RL) promises a framework for near-universal\nproblem-solving. In practice however, RL algorithms are often tailored to\nspecific benchmarks, relying on carefully tuned hyperparameters and algorithmic\nchoices. Recently, powerful model-based RL methods have shown impressive\ngeneral results across benchmarks but come at the cost of increased complexity\nand slow run times, limiting their broader applicability. In this paper, we\nattempt to find a unifying model-free deep RL algorithm that can address a\ndiverse class of domains and problem settings. To achieve this, we leverage\nmodel-based representations that approximately linearize the value function,\ntaking advantage of the denser task objectives used by model-based RL while\navoiding the costs associated with planning or simulated trajectories. We\nevaluate our algorithm, MR.Q, on a variety of common RL benchmarks with a\nsingle set of hyperparameters and show a competitive performance against\ndomain-specific and general baselines, providing a concrete step towards\nbuilding general-purpose model-free deep RL algorithms.",
            "upvotes": 10,
            "discussionId": "67986cbf7dbf69e4e3853a89"
        },
        "translation_title": "일반 목적의 모델 프리 강화 학습을 향하여",
        "purpose": "다양한 분야와 문제 설정을 해결할 수 있는 일반적인 모델 프리 심층 강화 학습 알고리즘 개발",
        "method": [
            "모델 기반 표현을 활용하여 가치 함수의 선형 근사를 시도함(we leverage model-based representations that approximately linearize the value function)",
            "모델 기반 RL에서 사용되는 밀집한 작업 목표를 활용하여 계획이나 시뮬레이션과 관련된 비용을 회피함(taking advantage of the denser task objectives used by model-based RL while avoiding the costs associated with planning or simulated trajectories)",
            "단일 하이퍼파라미터 집합으로 다양한 RL 벤치마크에서 알고리즘 MR.Q의 성능을 평가함(We evaluate our algorithm, MR.Q, on a variety of common RL benchmarks with a single set of hyperparameters)"
        ],
        "conclusion": "MR.Q는 도메인 별 및 일반 기준에 대해 경쟁력 있는 성능을 보이며, 일반 목적의 모델 프리 심층 강화 학습 알고리즘을 만들기 위한 구체적인 단계임",
        "keywords": [
            "Reinforcement Learning",
            "Model-Free",
            "Deep Learning"
        ]
    },
    {
        "paper": {
            "id": "2501.15570",
            "authors": [
                {
                    "_id": "679843ae7d7b7f8196c61ab7",
                    "user": {
                        "_id": "63a00aa29f1f2baab2034cf8",
                        "avatarUrl": "/avatars/818d104f45cbce2c47d443756fa806c8.svg",
                        "isPro": false,
                        "fullname": "Yueyu Lin",
                        "user": "yueyulin",
                        "type": "user"
                    },
                    "name": "Lin Yueyu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:10:34.376Z",
                    "hidden": false
                },
                {
                    "_id": "679843ae7d7b7f8196c61ab8",
                    "name": "Li Zhiyuan",
                    "hidden": false
                },
                {
                    "_id": "679843ae7d7b7f8196c61ab9",
                    "user": {
                        "_id": "64087a0992033c15073afb8c",
                        "avatarUrl": "/avatars/9c590ab5c6526edce5084169ec7bde2e.svg",
                        "isPro": false,
                        "fullname": "peteryue",
                        "user": "peteryue",
                        "type": "user"
                    },
                    "name": "Peter Yue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:11:02.358Z",
                    "hidden": false
                },
                {
                    "_id": "679843ae7d7b7f8196c61aba",
                    "user": {
                        "_id": "6176b32847ee6431f632981e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6176b32847ee6431f632981e/02rZ_oLAI0Ll6Y6be7Q9F.jpeg",
                        "isPro": false,
                        "fullname": "IvanD",
                        "user": "xiaol",
                        "type": "user"
                    },
                    "name": "Liu Xiao",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2025-01-28T02:44:02.658Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-26T15:56:56.000Z",
            "title": "ARWKV: Pretrain is not what we need, an RNN-Attention-Based Language\n  Model Born from Transformer",
            "summary": "As is known, hybrid quadratic and subquadratic attention models in multi-head\narchitectures have surpassed both Transformer and Linear RNN models , with\nthese works primarily focusing on reducing KV complexity and improving\nefficiency. For further research on expressiveness, we introduce our series of\nmodels distilled from Qwen 2.5, based on pure native RWKV-7 attention, which\naims to make RNN more expressive and demonstrates state tracking ability beyond\ntransformers. We work with QRWK 32B based on RWKV-6 architecture, another\napproach that reduces the entire knowledge processing time to just 8 hours\nusing 16 AMD MI300X GPUs while maintaining Qwen 2.5's performance. In fact, the\ndistillation process can utilize any LLM, not just Qwen, and enables knowledge\ntransfer from larger LLMs to smaller ones with more fewer tokens. We will\nexplain the detailed process and share our insights on building more powerful\nfoundation models. Please note that this is an ongoing work that will be\nupdated continuously. The model checkpoints and source code are available at\nhttps://github.com/yynil/RWKVInside{https://github.com/yynil/RWKVInside},\nhttps://huggingface.co/RWKV-Red-Team/ARWKV-7B-Preview-0.1{https://huggingface.co/RWKV-Red-Team/ARWKV-7B-Preview-0.1}.",
            "upvotes": 7,
            "discussionId": "679843af7d7b7f8196c61b21"
        },
        "translation_title": "ARWKV: 우리가 필요한 것은 Pretrain이 아니다, Transformer에서 태어난 RNN-Attention 기반 언어 모델",
        "purpose": "RNN의 표현력을 향상시키고 Transformer를 넘어서는 상태 추적 능력을 보여주기 위한 연구",
        "method": [
            "RWKV-7 어텐션 기반의 모델을 도입하여 RNN의 표현력을 강화함(we introduce our series of models distilled from Qwen 2.5, based on pure native RWKV-7 attention, which aims to make RNN more expressive)",
            "RWKV-6 아키텍처에 기반한 QRWK 32B 모델을 사용하여 16개의 AMD MI300X GPU로 전체 지식 처리 시간을 8시간으로 단축함(we work with QRWK 32B based on RWKV-6 architecture, another approach that reduces the entire knowledge processing time to just 8 hours using 16 AMD MI300X GPUs)",
            "모든 LLM을 활용할 수 있는 증류 과정을 설명하며, 더 큰 LLM에서 더 작은 LLM으로의 지식 전이를 가능하게 함(the distillation process can utilize any LLM, not just Qwen, and enables knowledge transfer from larger LLMs to smaller ones with more fewer tokens)"
        ],
        "conclusion": "우리는 더 강력한 기본 모델을 구축하는 데 대한 통찰력을 공유하며, 이 연구는 지속적으로 업데이트될 예정이고, 모델 체크포인트와 소스 코드는 공개되어 있음",
        "keywords": [
            "Large Language Models",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2501.15907",
            "authors": [
                {
                    "_id": "6798a917a8b0d165e39e17f5",
                    "user": {
                        "_id": "61a7569eaf0333e76eb428a8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61a7569eaf0333e76eb428a8/zwseNheR4Hx0DtCmf_v5H.jpeg",
                        "isPro": false,
                        "fullname": "HarryHe11",
                        "user": "HarryHe",
                        "type": "user"
                    },
                    "name": "Haorui He",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-28T13:52:52.095Z",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17f6",
                    "user": {
                        "_id": "64b77dd308e2452d18ddd279",
                        "avatarUrl": "/avatars/258f21fa20a3a187050d80c6088a1f50.svg",
                        "isPro": false,
                        "fullname": "shangzengqiang",
                        "user": "clatter-1",
                        "type": "user"
                    },
                    "name": "Zengqiang Shang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:12:12.565Z",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17f7",
                    "name": "Chaoren Wang",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17f8",
                    "name": "Xuyuan Li",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17f9",
                    "user": {
                        "_id": "66b5f38a080d890d1727a2a4",
                        "avatarUrl": "/avatars/4d73017ce888437225d994d8ba370e5d.svg",
                        "isPro": false,
                        "fullname": "guyicheng",
                        "user": "guyicheng",
                        "type": "user"
                    },
                    "name": "Yicheng Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:12:57.932Z",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17fa",
                    "name": "Hua Hua",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17fb",
                    "name": "Liwei Liu",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17fc",
                    "name": "Chen Yang",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17fd",
                    "user": {
                        "_id": "6635a711a5243c9638f5e4df",
                        "avatarUrl": "/avatars/08651622fc1fd5089551b510be8c4530.svg",
                        "isPro": false,
                        "fullname": "Jiaqi Li",
                        "user": "jiaqili3",
                        "type": "user"
                    },
                    "name": "Jiaqi Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:14:30.597Z",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17fe",
                    "name": "Peiyang Shi",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e17ff",
                    "user": {
                        "_id": "63072d60cd148dbc5e49f4dd",
                        "avatarUrl": "/avatars/ffa61038c0ff20848fbcde7c1c34570e.svg",
                        "isPro": false,
                        "fullname": "Yuancheng Wang",
                        "user": "Hecheng0625",
                        "type": "user"
                    },
                    "name": "Yuancheng Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:14:50.950Z",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e1800",
                    "name": "Kai Chen",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e1801",
                    "user": {
                        "_id": "65fbe8eb030389a29b87446f",
                        "avatarUrl": "/avatars/6d3ba153c41945e566b7c2c2d6af6da6.svg",
                        "isPro": false,
                        "fullname": "pengyuan zhang",
                        "user": "pengyuan2024",
                        "type": "user"
                    },
                    "name": "Pengyuan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-28T14:14:57.414Z",
                    "hidden": false
                },
                {
                    "_id": "6798a917a8b0d165e39e1802",
                    "name": "Zhizheng Wu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-27T09:59:20.000Z",
            "title": "Emilia: A Large-Scale, Extensive, Multilingual, and Diverse Dataset for\n  Speech Generation",
            "summary": "Recent advancements in speech generation have been driven by the large-scale\ntraining datasets. However, current models fall short of capturing the\nspontaneity and variability inherent in real-world human speech, due to their\nreliance on audiobook datasets limited to formal read-aloud speech styles. To\nbridge this gap, we introduce Emilia-Pipe, an open-source preprocessing\npipeline to extract high-quality training data from valuable yet underexplored\nin-the-wild data that capture spontaneous human speech in real-world contexts.\nBy leveraging Emilia-Pipe, we construct Emilia, the first multilingual speech\ngeneration dataset derived from in-the-wild speech data. This dataset comprises\nover 101k hours of speech across six languages: English, Chinese, German,\nFrench, Japanese, and Korean. Besides, we expand Emilia to Emilia-Large, a\ndataset exceeding 216k hours, making it the largest open-source speech\ngeneration dataset available. Extensive experiments demonstrate that Emilia\nsignificantly outperforms traditional audiobook datasets in generating\nspontaneous and human-like speech, showcasing superior performance in capturing\ndiverse speaker timbre and speaking styles of real-world human speech.\nFurthermore, this work underscores the importance of scaling dataset size to\nadvance speech generation research and validates the effectiveness of Emilia\nfor both multilingual and crosslingual speech generation.",
            "upvotes": 6,
            "discussionId": "6798a919a8b0d165e39e187d"
        },
        "translation_title": "Emilia: 대규모 다국어 및 다양한 음성 생성을 위한 데이터셋",
        "purpose": "다양한 현실적 맥락을 반영하는 자연스러운 음성 생성을 위한 대규모 데이터셋 구축",
        "method": [
            "Emilia-Pipe라는 오픈소스 전처리 파이프라인을 도입해 현실 세계의 자연스러운 음성을 캡처한 데이터 수집(we introduce Emilia-Pipe, an open-source preprocessing pipeline to extract high-quality training data from valuable yet underexplored in-the-wild data that capture spontaneous human speech in real-world contexts.)",
            "6개 언어에서 101k 시간 이상의 음성을 포함한 다국어 음성 생성 데이터셋 Emilia를 구축함( we construct Emilia, the first multilingual speech generation dataset derived from in-the-wild speech data. This dataset comprises over 101k hours of speech across six languages: English, Chinese, German, French, Japanese, and Korean.)",
            "Emilia 데이터셋을 216k 시간 이상의 음성을 포함한 Emilia-Large로 확장함(This dataset comprises over 101k hours of speech across six languages: English, Chinese, German, French, Japanese, and Korean.)",
            "철저한 실험을 통해 Emilia가 전통적인 오디오북 데이터셋보다 자연스럽고 사람 같은 음성을 생성함을 보여줌(Extensive experiments demonstrate that Emilia significantly outperforms traditional audiobook datasets in generating spontaneous and human-like speech.)"
        ],
        "conclusion": "Emilia는 다국어 및 교차 언어 음성 생성에서 뛰어난 성능을 보여주며, 음성 생성 연구를 발전시키기 위해 데이터셋 규모 확대의 중요성을 강조함.",
        "keywords": [
            "Speech Generation",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    }
]