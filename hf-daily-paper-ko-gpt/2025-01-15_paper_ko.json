[
    {
        "paper": {
            "id": "2501.08313",
            "authors": [
                {
                    "_id": "67871e6ef492fb2235af8978",
                    "name": "MiniMax",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8979",
                    "name": "Aonian Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af897a",
                    "name": "Bangwei Gong",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af897b",
                    "name": "Bo Yang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af897c",
                    "name": "Boji Shan",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af897d",
                    "name": "Chang Liu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af897e",
                    "name": "Cheng Zhu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af897f",
                    "user": {
                        "_id": "642662fa22bddcea3d289f0a",
                        "avatarUrl": "/avatars/9b28e1325d866a24d33fdfafcaa85c4b.svg",
                        "isPro": false,
                        "fullname": "Enoch Zhang",
                        "user": "enochzhang",
                        "type": "user"
                    },
                    "name": "Chunhao Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-15T08:48:51.874Z",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8980",
                    "name": "Congchao Guo",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8981",
                    "name": "Da Chen",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8982",
                    "name": "Dong Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8983",
                    "name": "Enwei Jiao",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8984",
                    "name": "Gengxin Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8985",
                    "name": "Guojun Zhang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8986",
                    "name": "Haohai Sun",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8987",
                    "name": "Houze Dong",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8988",
                    "name": "Jiadai Zhu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8989",
                    "name": "Jiaqi Zhuang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af898a",
                    "name": "Jiayuan Song",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af898b",
                    "name": "Jin Zhu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af898c",
                    "name": "Jingtao Han",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af898d",
                    "name": "Jingyang Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af898e",
                    "name": "Junbin Xie",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af898f",
                    "name": "Junhao Xu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8990",
                    "name": "Junjie Yan",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8991",
                    "name": "Kaishun Zhang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8992",
                    "name": "Kecheng Xiao",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8993",
                    "name": "Kexi Kang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8994",
                    "name": "Le Han",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8995",
                    "name": "Leyang Wang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8996",
                    "name": "Lianfei Yu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8997",
                    "name": "Liheng Feng",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8998",
                    "name": "Lin Zheng",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af8999",
                    "name": "Linbo Chai",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af899a",
                    "name": "Long Xing",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af899b",
                    "name": "Meizhi Ju",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af899c",
                    "name": "Mingyuan Chi",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af899d",
                    "name": "Mozhi Zhang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af899e",
                    "name": "Peikai Huang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af899f",
                    "name": "Pengcheng Niu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a0",
                    "name": "Pengfei Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a1",
                    "name": "Pengyu Zhao",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a2",
                    "name": "Qi Yang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a3",
                    "name": "Qidi Xu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a4",
                    "name": "Qiexiang Wang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a5",
                    "name": "Qin Wang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a6",
                    "name": "Qiuhui Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a7",
                    "name": "Ruitao Leng",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a8",
                    "name": "Shengmin Shi",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89a9",
                    "name": "Shuqi Yu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89aa",
                    "name": "Sichen Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89ab",
                    "name": "Songquan Zhu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89ac",
                    "name": "Tao Huang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89ad",
                    "name": "Tianrun Liang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89ae",
                    "name": "Weigao Sun",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89af",
                    "name": "Weixuan Sun",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b0",
                    "name": "Weiyu Cheng",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b1",
                    "name": "Wenkai Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b2",
                    "name": "Xiangjun Song",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b3",
                    "name": "Xiao Su",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b4",
                    "user": {
                        "_id": "64638bddc615cbc12447f9f1",
                        "avatarUrl": "/avatars/52910d1717451ff983f745322e5850dd.svg",
                        "isPro": false,
                        "fullname": "Xiaodong Han",
                        "user": "Hannnnnxd",
                        "type": "user"
                    },
                    "name": "Xiaodong Han",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-15T08:48:47.808Z",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b5",
                    "name": "Xinjie Zhang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b6",
                    "name": "Xinzhu Hou",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b7",
                    "name": "Xu Min",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b8",
                    "name": "Xun Zou",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89b9",
                    "name": "Xuyang Shen",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89ba",
                    "name": "Yan Gong",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89bb",
                    "name": "Yingjie Zhu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89bc",
                    "name": "Yipeng Zhou",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89bd",
                    "name": "Yiran Zhong",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89be",
                    "name": "Yongyi Hu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89bf",
                    "name": "Yuanxiang Fan",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c0",
                    "name": "Yue Yu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c1",
                    "name": "Yufeng Yang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c2",
                    "name": "Yuhao Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c3",
                    "name": "Yunan Huang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c4",
                    "name": "Yunji Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c5",
                    "name": "Yunpeng Huang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c6",
                    "name": "Yunzhi Xu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c7",
                    "name": "Yuxin Mao",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c8",
                    "name": "Zehan Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89c9",
                    "name": "Zekang Li",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89ca",
                    "name": "Zewei Tao",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89cb",
                    "name": "Zewen Ying",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89cc",
                    "name": "Zhaoyang Cong",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89cd",
                    "name": "Zhen Qin",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89ce",
                    "name": "Zhenhua Fan",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89cf",
                    "name": "Zhihang Yu",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89d0",
                    "name": "Zhuo Jiang",
                    "hidden": false
                },
                {
                    "_id": "67871e6ef492fb2235af89d1",
                    "name": "Zijia Wu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-14T18:50:05.000Z",
            "title": "MiniMax-01: Scaling Foundation Models with Lightning Attention",
            "summary": "We introduce MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01,\nwhich are comparable to top-tier models while offering superior capabilities in\nprocessing longer contexts. The core lies in lightning attention and its\nefficient scaling. To maximize computational capacity, we integrate it with\nMixture of Experts (MoE), creating a model with 32 experts and 456 billion\ntotal parameters, of which 45.9 billion are activated for each token. We\ndevelop an optimized parallel strategy and highly efficient\ncomputation-communication overlap techniques for MoE and lightning attention.\nThis approach enables us to conduct efficient training and inference on models\nwith hundreds of billions of parameters across contexts spanning millions of\ntokens. The context window of MiniMax-Text-01 can reach up to 1 million tokens\nduring training and extrapolate to 4 million tokens during inference at an\naffordable cost. Our vision-language model, MiniMax-VL-01 is built through\ncontinued training with 512 billion vision-language tokens. Experiments on both\nstandard and in-house benchmarks show that our models match the performance of\nstate-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering 20-32\ntimes longer context window. We publicly release MiniMax-01 at\nhttps://github.com/MiniMax-AI.",
            "upvotes": 178,
            "discussionId": "67871e6ff492fb2235af8a6a"
        },
        "translation_title": "MiniMax-01: 라이트닝 어텐션으로 기반 모델 확장하기",
        "purpose": "긴 문맥 처리에서 뛰어난 성능을 발휘하는 모델 개발.",
        "method": [
            "라이트닝 어텐션과 Mixture of Experts (MoE)를 통합하여 32명의 전문가와 4560억 개의 총 파라미터를 가진 모델을 생성함.(To maximize computational capacity, we integrate it with Mixture of Experts (MoE), creating a model with 32 experts and 456 billion total parameters.)",
            "최적화된 병렬 전략과 효율적인 계산-통신 겹침 기술을 개발함.(We develop an optimized parallel strategy and highly efficient computation-communication overlap techniques for MoE and lightning attention.)",
            "MiniMax-Text-01의 훈련 중 최대 100만 개의 토큰을 처리하고, 추론에서는 400만 개의 토큰으로 확장함.(The context window of MiniMax-Text-01 can reach up to 1 million tokens during training and extrapolate to 4 million tokens during inference at an affordable cost.)"
        ],
        "conclusion": "MiniMax-01은 GPT-4o 및 Claude-3.5-Sonnet과 같은 최첨단 모델의 성능에 필적하며, 20-32배 더 긴 문맥을 처리할 수 있음.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Vision-Language Models"
        ]
    },
    {
        "paper": {
            "id": "2501.06751",
            "authors": [
                {
                    "_id": "67876c0783ec692b4570e0af",
                    "name": "Michael Toker",
                    "hidden": false
                },
                {
                    "_id": "67876c0783ec692b4570e0b0",
                    "name": "Ido Galil",
                    "hidden": false
                },
                {
                    "_id": "67876c0783ec692b4570e0b1",
                    "name": "Hadas Orgad",
                    "hidden": false
                },
                {
                    "_id": "67876c0783ec692b4570e0b2",
                    "name": "Rinon Gal",
                    "hidden": false
                },
                {
                    "_id": "67876c0783ec692b4570e0b3",
                    "name": "Yoad Tewel",
                    "hidden": false
                },
                {
                    "_id": "67876c0783ec692b4570e0b4",
                    "name": "Gal Chechik",
                    "hidden": false
                },
                {
                    "_id": "67876c0783ec692b4570e0b5",
                    "name": "Yonatan Belinkov",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-12T08:36:38.000Z",
            "title": "Padding Tone: A Mechanistic Analysis of Padding Tokens in T2I Models",
            "summary": "Text-to-image (T2I) diffusion models rely on encoded prompts to guide the\nimage generation process. Typically, these prompts are extended to a fixed\nlength by adding padding tokens before text encoding. Despite being a default\npractice, the influence of padding tokens on the image generation process has\nnot been investigated. In this work, we conduct the first in-depth analysis of\nthe role padding tokens play in T2I models. We develop two causal techniques to\nanalyze how information is encoded in the representation of tokens across\ndifferent components of the T2I pipeline. Using these techniques, we\ninvestigate when and how padding tokens impact the image generation process.\nOur findings reveal three distinct scenarios: padding tokens may affect the\nmodel's output during text encoding, during the diffusion process, or be\neffectively ignored. Moreover, we identify key relationships between these\nscenarios and the model's architecture (cross or self-attention) and its\ntraining process (frozen or trained text encoder). These insights contribute to\na deeper understanding of the mechanisms of padding tokens, potentially\ninforming future model design and training practices in T2I systems.",
            "upvotes": 25,
            "discussionId": "67876c0d83ec692b4570e1ec"
        },
        "translation_title": "Padding Tone: T2I 모델에서 패딩 토큰의 기계적 분석",
        "purpose": "T2I 모델에서 패딩 토큰이 이미지 생성 과정에 미치는 영향을 조사하는 것",
        "method": [
            "T2I 파이프라인의 다양한 요소에서 토큰 표현의 정보 인코딩을 분석하기 위해 두 가지 인과적 기법을 개발함(We develop two causal techniques to analyze how information is encoded in the representation of tokens across different components of the T2I pipeline.)",
            "패딩 토큰이 이미지 생성 과정에 미치는 영향을 조사함(Using these techniques, we investigate when and how padding tokens impact the image generation process.)"
        ],
        "conclusion": "패딩 토큰이 텍스트 인코딩, 확산 과정 또는 무시되는 상황에서 모델의 출력에 영향을 줄 수 있는 세 가지 다른 시나리오를 밝혀내어 T2I 시스템의 모델 설계 및 훈련 관행에 대한 통찰력을 제공함.",
        "keywords": [
            "Image Generation",
            "Computer Vision",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2501.08332",
            "authors": [
                {
                    "_id": "678727aadd2e5dbecdf08fe3",
                    "name": "Zhiheng Liu",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fe4",
                    "name": "Ka Leong Cheng",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fe5",
                    "name": "Xi Chen",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fe6",
                    "name": "Jie Xiao",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fe7",
                    "name": "Hao Ouyang",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fe8",
                    "name": "Kai Zhu",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fe9",
                    "name": "Yu Liu",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fea",
                    "name": "Yujun Shen",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08feb",
                    "name": "Qifeng Chen",
                    "hidden": false
                },
                {
                    "_id": "678727aadd2e5dbecdf08fec",
                    "name": "Ping Luo",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-14T18:59:55.000Z",
            "title": "MangaNinja: Line Art Colorization with Precise Reference Following",
            "summary": "Derived from diffusion models, MangaNinjia specializes in the task of\nreference-guided line art colorization. We incorporate two thoughtful designs\nto ensure precise character detail transcription, including a patch shuffling\nmodule to facilitate correspondence learning between the reference color image\nand the target line art, and a point-driven control scheme to enable\nfine-grained color matching. Experiments on a self-collected benchmark\ndemonstrate the superiority of our model over current solutions in terms of\nprecise colorization. We further showcase the potential of the proposed\ninteractive point control in handling challenging cases, cross-character\ncolorization, multi-reference harmonization, beyond the reach of existing\nalgorithms.",
            "upvotes": 25,
            "discussionId": "678727acdd2e5dbecdf09097"
        },
        "translation_title": "MangaNinja: 정밀 참조에 따른 선화 색칠화",
        "purpose": "정확한 캐릭터 세부 묘사를 보장하는 선화 색칠화 기술 개발",
        "method": [
            "참조 색상 이미지와 목표 선화 간의 대응 학습을 촉진하는 패치 셔플링 모듈을 도입함 (we incorporate a patch shuffling module to facilitate correspondence learning between the reference color image and the target line art.)",
            "정밀한 색상 매칭을 가능하게 하는 포인트 구동 제어 방식을 사용함 (and a point-driven control scheme to enable fine-grained color matching.)",
            "자체 수집한 벤치마크 실험을 통해 기존 솔루션보다 우수한 성능을 입증함 (Experiments on a self-collected benchmark demonstrate the superiority of our model over current solutions in terms of precise colorization.)"
        ],
        "conclusion": "MangaNinja는 기존 알고리즘으로는 처리하기 어려운 복잡한 색칠화 문제를 해결할 수 있는 잠재력을 보여줌.",
        "keywords": [
            "Computer Vision",
            "Image Generation",
            "Image Segmentation"
        ]
    },
    {
        "paper": {
            "id": "2501.08187",
            "authors": [
                {
                    "_id": "67871cb6ce7f3eb12692b222",
                    "user": {
                        "_id": "63d660ae44f1d8fbe585d463",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674993743489-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Yin Fang",
                        "user": "Fangyinfff",
                        "type": "user"
                    },
                    "name": "Yin Fang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-15T08:48:58.033Z",
                    "hidden": false
                },
                {
                    "_id": "67871cb6ce7f3eb12692b223",
                    "name": "Xinle Deng",
                    "hidden": false
                },
                {
                    "_id": "67871cb6ce7f3eb12692b224",
                    "name": "Kangwei Liu",
                    "hidden": false
                },
                {
                    "_id": "67871cb6ce7f3eb12692b225",
                    "user": {
                        "_id": "620b3bbb0668e435407c8d0a",
                        "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
                        "isPro": false,
                        "fullname": "Ningyu Zhang",
                        "user": "Ningyu",
                        "type": "user"
                    },
                    "name": "Ningyu Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-15T08:48:54.355Z",
                    "hidden": false
                },
                {
                    "_id": "67871cb6ce7f3eb12692b226",
                    "name": "Jingyang Qian",
                    "hidden": false
                },
                {
                    "_id": "67871cb6ce7f3eb12692b227",
                    "name": "Penghui Yang",
                    "hidden": false
                },
                {
                    "_id": "67871cb6ce7f3eb12692b228",
                    "name": "Xiaohui Fan",
                    "hidden": false
                },
                {
                    "_id": "67871cb6ce7f3eb12692b229",
                    "name": "Huajun Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-14T15:12:19.000Z",
            "title": "A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction\n  Following",
            "summary": "Large language models excel at interpreting complex natural language\ninstructions, enabling them to perform a wide range of tasks. In the life\nsciences, single-cell RNA sequencing (scRNA-seq) data serves as the \"language\nof cellular biology\", capturing intricate gene expression patterns at the\nsingle-cell level. However, interacting with this \"language\" through\nconventional tools is often inefficient and unintuitive, posing challenges for\nresearchers. To address these limitations, we present InstructCell, a\nmulti-modal AI copilot that leverages natural language as a medium for more\ndirect and flexible single-cell analysis. We construct a comprehensive\nmulti-modal instruction dataset that pairs text-based instructions with\nscRNA-seq profiles from diverse tissues and species. Building on this, we\ndevelop a multi-modal cell language architecture capable of simultaneously\ninterpreting and processing both modalities. InstructCell empowers researchers\nto accomplish critical tasks-such as cell type annotation, conditional\npseudo-cell generation, and drug sensitivity prediction-using straightforward\nnatural language commands. Extensive evaluations demonstrate that InstructCell\nconsistently meets or exceeds the performance of existing single-cell\nfoundation models, while adapting to diverse experimental conditions. More\nimportantly, InstructCell provides an accessible and intuitive tool for\nexploring complex single-cell data, lowering technical barriers and enabling\ndeeper biological insights.",
            "upvotes": 17,
            "discussionId": "67871cbcce7f3eb12692b37e"
        },
        "translation_title": "지시사항 기반 단일 세포 분석을 위한 다중 모달 AI 코파일럿",
        "purpose": "전통적인 도구의 비효율성과 직관적이지 않은 상호작용 문제를 해결하여 단일 세포 분석을 보다 직관적이고 유연하게 수행하기 위한 연구",
        "method": [
            "자연어를 매개로 하여 단일 세포 RNA 시퀀싱(scRNA-seq) 데이터를 분석할 수 있는 다중 모달 AI 코파일럿 InstructCell을 제시함(we present InstructCell, a multi-modal AI copilot that leverages natural language as a medium for more direct and flexible single-cell analysis.)",
            "다양한 조직과 종의 scRNA-seq 프로필과 텍스트 지시사항을 쌍으로 구성한 포괄적인 다중 모달 지시 데이터셋을 구축함(We construct a comprehensive multi-modal instruction dataset that pairs text-based instructions with scRNA-seq profiles from diverse tissues and species.)",
            "다중 모달 셀 언어 아키텍처를 개발하여 두 가지 형식을 동시에 해석 및 처리할 수 있도록 함(We develop a multi-modal cell language architecture capable of simultaneously interpreting and processing both modalities.)"
        ],
        "conclusion": "InstructCell은 기존의 단일 세포 기본 모델들의 성능을 지속적으로 초과하며, 복잡한 단일 세포 데이터를 탐색하는 데 있어 접근성과 직관성을 제공함.",
        "keywords": [
            "Natural Language Processing",
            "Single-Cell Analysis",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2501.08316",
            "authors": [
                {
                    "_id": "678725b38c1e7b6c4a69f88a",
                    "user": {
                        "_id": "645863f7dc18eb1a9b5d29df",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645863f7dc18eb1a9b5d29df/t49Nnyl4tbkUn7CmQqKZh.jpeg",
                        "isPro": false,
                        "fullname": "Peter Lin",
                        "user": "PeterL1n",
                        "type": "user"
                    },
                    "name": "Shanchuan Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-15T08:48:34.462Z",
                    "hidden": false
                },
                {
                    "_id": "678725b38c1e7b6c4a69f88b",
                    "name": "Xin Xia",
                    "hidden": false
                },
                {
                    "_id": "678725b38c1e7b6c4a69f88c",
                    "name": "Yuxi Ren",
                    "hidden": false
                },
                {
                    "_id": "678725b38c1e7b6c4a69f88d",
                    "name": "Ceyuan Yang",
                    "hidden": false
                },
                {
                    "_id": "678725b38c1e7b6c4a69f88e",
                    "name": "Xuefeng Xiao",
                    "hidden": false
                },
                {
                    "_id": "678725b38c1e7b6c4a69f88f",
                    "name": "Lu Jiang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-14T18:51:48.000Z",
            "title": "Diffusion Adversarial Post-Training for One-Step Video Generation",
            "summary": "The diffusion models are widely used for image and video generation, but\ntheir iterative generation process is slow and expansive. While existing\ndistillation approaches have demonstrated the potential for one-step generation\nin the image domain, they still suffer from significant quality degradation. In\nthis work, we propose Adversarial Post-Training (APT) against real data\nfollowing diffusion pre-training for one-step video generation. To improve the\ntraining stability and quality, we introduce several improvements to the model\narchitecture and training procedures, along with an approximated R1\nregularization objective. Empirically, our experiments show that our\nadversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720,\n24fps videos in real time using a single forward evaluation step. Additionally,\nour model is capable of generating 1024px images in a single step, achieving\nquality comparable to state-of-the-art methods.",
            "upvotes": 16,
            "discussionId": "678725b68c1e7b6c4a69f911"
        },
        "translation_title": "한 단계 비디오 생성을 위한 확산 적대적 후 훈련",
        "purpose": "한 단계 비디오 생성의 품질을 높이고 생성을 빠르게 수행하기 위한 새로운 방법 연구",
        "method": [
            "확산 사전 훈련 후 실제 데이터를 이용한 적대적 후 훈련(We propose Adversarial Post-Training (APT) against real data following diffusion pre-training for one-step video generation.)",
            "모델 아키텍처와 훈련 절차에 여러 가지 개선 사항을 도입함(To improve the training stability and quality, we introduce several improvements to the model architecture and training procedures.)",
            "R1 정규화 목표를 사용하여 훈련 안정성을 더함(Along with an approximated R1 regularization objective.)"
        ],
        "conclusion": "Seaweed-APT 모델을 사용하면 실시간으로 2초, 1280x720, 24fps 비디오를 한 번의 평가 단계로 생성할 수 있으며, 1024px 이미지를 한 단계에서 생성하여 최첨단 방법과 유사한 품질을 달성함.",
        "keywords": [
            "Video Generation",
            "Image Generation",
            "Multimodal Learning"
        ]
    }
]