[
    {
        "paper": {
            "id": "2412.17256",
            "authors": [
                {
                    "_id": "676a23c19fc612bf4a3b93f6",
                    "name": "Weihao Zeng",
                    "hidden": false
                },
                {
                    "_id": "676a23c19fc612bf4a3b93f7",
                    "name": "Yuzhen Huang",
                    "hidden": false
                },
                {
                    "_id": "676a23c19fc612bf4a3b93f8",
                    "name": "Lulu Zhao",
                    "hidden": false
                },
                {
                    "_id": "676a23c19fc612bf4a3b93f9",
                    "name": "Yijun Wang",
                    "hidden": false
                },
                {
                    "_id": "676a23c19fc612bf4a3b93fa",
                    "name": "Zifei Shan",
                    "hidden": false
                },
                {
                    "_id": "676a23c19fc612bf4a3b93fb",
                    "name": "Junxian He",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-23T03:58:34.000Z",
            "title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in\n  Self-Taught Reasoners",
            "summary": "In the absence of extensive human-annotated data for complex reasoning tasks,\nself-improvement -- where models are trained on their own outputs -- has\nemerged as a primary method for enhancing performance. However, the critical\nfactors underlying the mechanism of these iterative self-improving methods\nremain poorly understood, such as under what conditions self-improvement is\neffective, and what are the bottlenecks in the current iterations. In this\nwork, we identify and propose methods to monitor two pivotal factors in this\niterative process: (1) the model's ability to generate sufficiently diverse\nresponses (exploration); and (2) the effectiveness of external rewards in\ndistinguishing high-quality candidates from lower-quality ones (exploitation).\nUsing mathematical reasoning as a case study, we begin with a quantitative\nanalysis to track the dynamics of exploration and exploitation, discovering\nthat a model's exploratory capabilities rapidly deteriorate over iterations,\nand the effectiveness of exploiting external rewards diminishes as well.\nMotivated by these findings, we introduce B-STaR, a Self-Taught Reasoning\nframework that autonomously adjusts configurations across iterations to Balance\nexploration and exploitation, thereby optimizing the self-improving\neffectiveness based on the current policy model and available rewards. Our\nexperiments on mathematical reasoning, coding, and commonsense reasoning\ndemonstrate that B-STaR not only enhances the model's exploratory capabilities\nthroughout training but also achieves a more effective balance between\nexploration and exploitation, leading to superior performance.",
            "upvotes": 28,
            "discussionId": "676a23c29fc612bf4a3b943b"
        },
        "translation_title": "B-STaR: 자기 학습 추론기에서 탐색과 활용의 균형 모니터링",
        "purpose": "복잡한 추론 작업을 위한 데이터 부족 문제를 해결하고, 자기 개선의 효율성을 높이기 위한 탐색과 활용 메커니즘 연구",
        "method": [
            "모델의 다양한 응답 생성 능력(탐색)과 외부 보상의 효과(활용)를 모니터링할 수 있는 방법을 제안함(we identify and propose methods to monitor two pivotal factors in this iterative process: (1) the model's ability to generate sufficiently diverse responses (exploration); and (2) the effectiveness of external rewards in distinguishing high-quality candidates from lower-quality ones (exploitation).)",
            "B-STaR라는 자기 학습 추론 프레임워크를 도입하여 탐색과 활용의 균형을 맞춤(we introduce B-STaR, a Self-Taught Reasoning framework that autonomously adjusts configurations across iterations to Balance exploration and exploitation.)",
            "수학적 추론을 사례로 사용하여 탐색과 활용의 동력을 추적하기 위한 정량 분석을 수행함(we begin with a quantitative analysis to track the dynamics of exploration and exploitation.)"
        ],
        "conclusion": "B-STaR는 모델의 탐색 능력을 향상시키고 탐색과 활용 간의 균형을 효과적으로 맞추어 성능을 개선함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2412.14922",
            "authors": [
                {
                    "_id": "676a2354463437b5e1217e15",
                    "name": "Junyu Luo",
                    "hidden": false
                },
                {
                    "_id": "676a2354463437b5e1217e16",
                    "name": "Xiao Luo",
                    "hidden": false
                },
                {
                    "_id": "676a2354463437b5e1217e17",
                    "user": {
                        "_id": "665e2f9301ca1c80a0a311d2",
                        "avatarUrl": "/avatars/67c88b55b580e6db74df4d0091197cea.svg",
                        "isPro": false,
                        "fullname": "Kaize Ding",
                        "user": "kaize0409",
                        "type": "user"
                    },
                    "name": "Kaize Ding",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-12-24T02:58:28.896Z",
                    "hidden": false
                },
                {
                    "_id": "676a2354463437b5e1217e18",
                    "name": "Jingyang Yuan",
                    "hidden": false
                },
                {
                    "_id": "676a2354463437b5e1217e19",
                    "name": "Zhiping Xiao",
                    "hidden": false
                },
                {
                    "_id": "676a2354463437b5e1217e1a",
                    "name": "Ming Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-19T15:00:18.000Z",
            "title": "RobustFT: Robust Supervised Fine-tuning for Large Language Models under\n  Noisy Response",
            "summary": "Supervised fine-tuning (SFT) plays a crucial role in adapting large language\nmodels (LLMs) to specific domains or tasks. However, as demonstrated by\nempirical experiments, the collected data inevitably contains noise in\npractical applications, which poses significant challenges to model performance\non downstream tasks. Therefore, there is an urgent need for a noise-robust SFT\nframework to enhance model capabilities in downstream tasks. To address this\nchallenge, we introduce a robust SFT framework (RobustFT) that performs noise\ndetection and relabeling on downstream task data. For noise identification, our\napproach employs a multi-expert collaborative system with inference-enhanced\nmodels to achieve superior noise detection. In the denoising phase, we utilize\na context-enhanced strategy, which incorporates the most relevant and confident\nknowledge followed by careful assessment to generate reliable annotations.\nAdditionally, we introduce an effective data selection mechanism based on\nresponse entropy, ensuring only high-quality samples are retained for\nfine-tuning. Extensive experiments conducted on multiple LLMs across five\ndatasets demonstrate RobustFT's exceptional performance in noisy scenarios.",
            "upvotes": 25,
            "discussionId": "676a2354463437b5e1217e51"
        },
        "translation_title": "RobustFT: 노이즈가 있는 응답에서 대형 언어 모델을 위한 강인한 감독 미세 조정",
        "purpose": "노이즈가 포함된 데이터에서도 대형 언어 모델(LLMs)의 성능을 개선하기 위한 강인한 감독 미세 조정 프레임워크 구축",
        "method": [
            "다중 전문가 협업 시스템을 사용하여 데이터의 노이즈를 식별하고 더 나은 노이즈 감지를 수행함(To address this challenge, we introduce a robust SFT framework (RobustFT) that performs noise detection and relabeling on downstream task data.)",
            "컨텍스트 강화 전략을 통해 신뢰할 수 있는 주석을 생성함(in the denoising phase, we utilize a context-enhanced strategy, which incorporates the most relevant and confident knowledge followed by careful assessment to generate reliable annotations.)",
            "응답 엔트로피에 기반한 데이터 선택 메커니즘을 도입하여 고품질 샘플만 보유함(Additionally, we introduce an effective data selection mechanism based on response entropy, ensuring only high-quality samples are retained for fine-tuning.)"
        ],
        "conclusion": "RobustFT는 다양한 데이터셋에서 노이즈가 포함된 상황에서도 뛰어난 성능을 보임.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2412.17451",
            "authors": [
                {
                    "_id": "676a25e38ffab02f2c91a99e",
                    "name": "Wei Liu",
                    "hidden": false
                },
                {
                    "_id": "676a25e38ffab02f2c91a99f",
                    "name": "Junlong Li",
                    "hidden": false
                },
                {
                    "_id": "676a25e38ffab02f2c91a9a0",
                    "name": "Xiwen Zhang",
                    "hidden": false
                },
                {
                    "_id": "676a25e38ffab02f2c91a9a1",
                    "name": "Fan Zhou",
                    "hidden": false
                },
                {
                    "_id": "676a25e38ffab02f2c91a9a2",
                    "name": "Yu Cheng",
                    "hidden": false
                },
                {
                    "_id": "676a25e38ffab02f2c91a9a3",
                    "name": "Junxian He",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-23T10:18:41.000Z",
            "title": "Diving into Self-Evolving Training for Multimodal Reasoning",
            "summary": "Reasoning ability is essential for Large Multimodal Models (LMMs). In the\nabsence of multimodal chain-of-thought annotated data, self-evolving training,\nwhere the model learns from its own outputs, has emerged as an effective and\nscalable approach for enhancing reasoning abilities. Despite its growing usage,\na comprehensive understanding of self-evolving training, particularly in the\ncontext of multimodal reasoning, remains limited. In this paper, we delve into\nthe intricacies of self-evolving training for multimodal reasoning, pinpointing\nthree key factors: Training Method, Reward Model, and Prompt Variation. We\nsystematically examine each factor and explore how various configurations\naffect the training's effectiveness. Our analysis leads to a set of best\npractices for each factor, aimed at optimizing multimodal reasoning.\nFurthermore, we explore the Self-Evolution Dynamics during training and the\nimpact of automatic balancing mechanisms in boosting performance. After all the\ninvestigations, we present a final recipe for self-evolving training in\nmultimodal reasoning, encapsulating these design choices into a framework we\ncall MSTaR (Multimodal Self-evolving Training for Reasoning), which is\nuniversally effective for models with different sizes on various benchmarks,\ne.g., surpassing the pre-evolved model significantly on 5 multimodal reasoning\nbenchmarks without using additional human annotations, as demonstrated on\nMiniCPM-V-2.5 (8B), Phi-3.5-Vision (4B) and InternVL2 (2B). We believe this\nstudy fills a significant gap in the understanding of self-evolving training\nfor multimodal reasoning and offers a robust framework for future research. Our\npolicy and reward models, as well as the collected data, is released to\nfacilitate further investigation in multimodal reasoning.",
            "upvotes": 21,
            "discussionId": "676a25e48ffab02f2c91a9e3"
        },
        "translation_title": "다중 모달 추론을 위한 자기 진화 훈련 탐구",
        "purpose": "다중 모달 모델의 추론 능력을 향상시키기 위한 자기 진화 훈련의 이해와 최적화",
        "method": [
            "자기 진화 훈련의 세 가지 주요 요소인 훈련 방법, 보상 모델, 프롬프트 변화를 체계적으로 조사함(We systematically examine each factor and explore how various configurations affect the training's effectiveness.)",
            "효과성을 높이기 위한 최적의 방법을 도출하고, MSTaR라는 프레임워크로 설계 선택을 정리함(we present a final recipe for self-evolving training in multimodal reasoning, encapsulating these design choices into a framework we call MSTaR.)",
            "다양한 모델과 벤치마크에서 MSTaR의 일반적인 효과성을 보여줌(Which is universally effective for models with different sizes on various benchmarks.)"
        ],
        "conclusion": "MSTaR은 추가적인 인간 주석 없이도 여러 다중 모달 추론 벤치마크에서 사전 진화된 모델을 초월하는 성과를 달성함.",
        "keywords": [
            "Multimodal Learning",
            "Large Language Models",
            "Image Understanding"
        ]
    },
    {
        "paper": {
            "id": "2412.17747",
            "authors": [
                {
                    "_id": "676a3ec0b91a321e164a8780",
                    "name": "Luyang Liu",
                    "hidden": false
                },
                {
                    "_id": "676a3ec0b91a321e164a8781",
                    "name": "Jonas Pfeiffer",
                    "hidden": false
                },
                {
                    "_id": "676a3ec0b91a321e164a8782",
                    "name": "Jiaxing Wu",
                    "hidden": false
                },
                {
                    "_id": "676a3ec0b91a321e164a8783",
                    "name": "Jun Xie",
                    "hidden": false
                },
                {
                    "_id": "676a3ec0b91a321e164a8784",
                    "name": "Arthur Szlam",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-23T18:02:25.000Z",
            "title": "Deliberation in Latent Space via Differentiable Cache Augmentation",
            "summary": "Techniques enabling large language models (LLMs) to \"think more\" by\ngenerating and attending to intermediate reasoning steps have shown promise in\nsolving complex problems. However, the standard approaches generate sequences\nof discrete tokens immediately before responding, and so they can incur\nsignificant latency costs and be challenging to optimize. In this work, we\ndemonstrate that a frozen LLM can be augmented with an offline coprocessor that\noperates on the model's key-value (kv) cache. This coprocessor augments the\ncache with a set of latent embeddings designed to improve the fidelity of\nsubsequent decoding. We train this coprocessor using the language modeling loss\nfrom the decoder on standard pretraining data, while keeping the decoder itself\nfrozen. This approach enables the model to learn, in an end-to-end\ndifferentiable fashion, how to distill additional computation into its\nkv-cache. Because the decoder remains unchanged, the coprocessor can operate\noffline and asynchronously, and the language model can function normally if the\ncoprocessor is unavailable or if a given cache is deemed not to require extra\ncomputation. We show experimentally that when a cache is augmented, the decoder\nachieves lower perplexity on numerous subsequent tokens. Furthermore, even\nwithout any task-specific training, our experiments demonstrate that cache\naugmentation consistently reduces perplexity and improves performance across a\nrange of reasoning-intensive tasks.",
            "upvotes": 14,
            "discussionId": "676a3ec1b91a321e164a87ca"
        },
        "translation_title": "차별화된 캐시 증대를 통한 잠재 공간에서의 심사",
        "purpose": "대규모 언어 모델(LLMs)이 더 나은 문제 해결을 위해 중간 논리적 단계를 생성하고 주목할 수 있도록 개선하려는 목표",
        "method": [
            "모델의 kv-cache에서 작동하는 오프라인 보조 프로세서를 추가하여 LLM을 보강함(we demonstrate that a frozen LLM can be augmented with an offline coprocessor that operates on the model's key-value (kv) cache.)",
            "보조 프로세서를 훈련시켜 캐시의 신뢰성을 향상하도록 설계된 잠재 임베딩을 추가함(This coprocessor augments the cache with a set of latent embeddings designed to improve the fidelity of subsequent decoding.)",
            "디코더는 동결된 상태로 유지하며, 언어 모델링 손실을 활용해 보조 프로세서를 훈련함(This approach enables the model to learn, in an end-to-end differentiable fashion, how to distill additional computation into its kv-cache.)"
        ],
        "conclusion": "캐시가 증대되면 디코더가 여러 후속 토큰에서 낮은 perplexity를 달성하고, 다양한 논리적 문제에서 성능이 향상됨을 실험적으로 입증함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2412.17153",
            "authors": [
                {
                    "_id": "676a3070b1618113354d99fa",
                    "name": "Enshu Liu",
                    "hidden": false
                },
                {
                    "_id": "676a3070b1618113354d99fb",
                    "name": "Xuefei Ning",
                    "hidden": false
                },
                {
                    "_id": "676a3070b1618113354d99fc",
                    "name": "Yu Wang",
                    "hidden": false
                },
                {
                    "_id": "676a3070b1618113354d99fd",
                    "user": {
                        "_id": "64c832a8c547ed5243d29630",
                        "avatarUrl": "/avatars/59d1975634e84095b69423c02441d453.svg",
                        "isPro": false,
                        "fullname": "Zinan Lin",
                        "user": "fjxmlzn",
                        "type": "user"
                    },
                    "name": "Zinan Lin",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-12-24T03:54:58.649Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-22T20:21:54.000Z",
            "title": "Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models\n  with Flow Matching",
            "summary": "Autoregressive (AR) models have achieved state-of-the-art performance in text\nand image generation but suffer from slow generation due to the token-by-token\nprocess. We ask an ambitious question: can a pre-trained AR model be adapted to\ngenerate outputs in just one or two steps? If successful, this would\nsignificantly advance the development and deployment of AR models. We notice\nthat existing works that try to speed up AR generation by generating multiple\ntokens at once fundamentally cannot capture the output distribution due to the\nconditional dependencies between tokens, limiting their effectiveness for\nfew-step generation. To address this, we propose Distilled Decoding (DD), which\nuses flow matching to create a deterministic mapping from Gaussian distribution\nto the output distribution of the pre-trained AR model. We then train a network\nto distill this mapping, enabling few-step generation. DD doesn't need the\ntraining data of the original AR model, making it more practical.We evaluate DD\non state-of-the-art image AR models and present promising results on\nImageNet-256. For VAR, which requires 10-step generation, DD enables one-step\ngeneration (6.3times speed-up), with an acceptable increase in FID from 4.19\nto 9.96. For LlamaGen, DD reduces generation from 256 steps to 1, achieving an\n217.8times speed-up with a comparable FID increase from 4.11 to 11.35. In\nboth cases, baseline methods completely fail with FID>100. DD also excels on\ntext-to-image generation, reducing the generation from 256 steps to 2 for\nLlamaGen with minimal FID increase from 25.70 to 28.95. As the first work to\ndemonstrate the possibility of one-step generation for image AR models, DD\nchallenges the prevailing notion that AR models are inherently slow, and opens\nup new opportunities for efficient AR generation. The project website is at\nhttps://imagination-research.github.io/distilled-decoding.",
            "upvotes": 14,
            "discussionId": "676a3072b1618113354d9aa1"
        },
        "translation_title": "Distilled Decoding 1: 흐름 매칭을 이용한 이미지 자기회귀 모델의 원스텝 샘플링",
        "purpose": "이미지 생성에서 자기회귀 모델의 속도를 개선하고 효율적인 샘플링 방법을 개발하기 위함.",
        "method": [
            "예측된 AR 모델로부터 출력 분포의 결정적 매핑을 생성하기 위해 흐름 매칭을 통해 Distilled Decoding(DD)를 제안함(To address this, we propose Distilled Decoding (DD), which uses flow matching to create a deterministic mapping from Gaussian distribution to the output distribution of the pre-trained AR model.)",
            "DD는 원래 AR 모델의 훈련 데이터를 필요로 하지 않아 더 실용적임(DD doesn't need the training data of the original AR model, making it more practical.)",
            "시험 결과 DD는 최첨단 이미지 AR 모델에서 원스텝 생성과 함께 눈에 띄는 속도 향상을 보여줌(We evaluate DD on state-of-the-art image AR models and present promising results on ImageNet-256.)"
        ],
        "conclusion": "DD는 이미지 자기회귀 모델을 위한 원스텝 생성을 가능하게 하며, AR 모델의 기존 속도 저하 개념을 도전함.",
        "keywords": [
            "Image Generation",
            "Multimodal Learning",
            "Computer Vision"
        ]
    }
]