[
    {
        "paper": {
            "id": "2501.07301",
            "authors": [
                {
                    "_id": "6785e601117627fe711f8dd8",
                    "user": {
                        "_id": "64704e973601bb7b06643e98",
                        "avatarUrl": "/avatars/52e51f4d1be6769e4397b8be2799cf32.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "Zhenru",
                        "type": "user"
                    },
                    "name": "Zhenru Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:48:52.704Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8dd9",
                    "user": {
                        "_id": "610b70452719facd4ea85e28",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/610b70452719facd4ea85e28/S7nMy7D0Rxq0VIVblhYDG.jpeg",
                        "isPro": false,
                        "fullname": "Chujie Zheng",
                        "user": "chujiezheng",
                        "type": "user"
                    },
                    "name": "Chujie Zheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-14T08:28:43.769Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8dda",
                    "user": {
                        "_id": "671f2a2ab02f88b7e2385105",
                        "avatarUrl": "/avatars/a97e2f983c8290b72eeb03e2bdcaf085.svg",
                        "isPro": false,
                        "fullname": "Yangzhen Wu",
                        "user": "wuyangzhen",
                        "type": "user"
                    },
                    "name": "Yangzhen Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:49:01.963Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8ddb",
                    "user": {
                        "_id": "64b93578ee257c3a4cfceed1",
                        "avatarUrl": "/avatars/e6188562254f75a09b4048b800860016.svg",
                        "isPro": false,
                        "fullname": "Beichen Zhang",
                        "user": "BeichenZhang",
                        "type": "user"
                    },
                    "name": "Beichen Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:49:43.861Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8ddc",
                    "user": {
                        "_id": "649a52e5de0fb7f3f499e583",
                        "avatarUrl": "/avatars/25f6106fa168ae57ad5cd8ef55c70d31.svg",
                        "isPro": false,
                        "fullname": "Runji Lin",
                        "user": "RunjiLin",
                        "type": "user"
                    },
                    "name": "Runji Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:49:56.685Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8ddd",
                    "user": {
                        "_id": "6438b43ab2ea24b52ebac2b9",
                        "avatarUrl": "/avatars/84133cd719a4b1e2f5c1a74178425f86.svg",
                        "isPro": false,
                        "fullname": "Bowen Yu",
                        "user": "bwy",
                        "type": "user"
                    },
                    "name": "Bowen Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:50:12.316Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8dde",
                    "user": {
                        "_id": "6434d4989bd5a84b5dd0b0f5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg",
                        "isPro": false,
                        "fullname": "Dayiheng Liu",
                        "user": "Losin94",
                        "type": "user"
                    },
                    "name": "Dayiheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:50:18.536Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8ddf",
                    "user": {
                        "_id": "602f88f5e8149a962412a667",
                        "avatarUrl": "/avatars/b78f0e583df8e5d5e3365934fe5f4900.svg",
                        "isPro": false,
                        "fullname": "Zhou",
                        "user": "Jingren",
                        "type": "user"
                    },
                    "name": "Jingren Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:50:29.301Z",
                    "hidden": false
                },
                {
                    "_id": "6785e601117627fe711f8de0",
                    "user": {
                        "_id": "620760a26e3b7210c2ff1943",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
                        "isPro": false,
                        "fullname": "Junyang Lin",
                        "user": "JustinLin610",
                        "type": "user"
                    },
                    "name": "Junyang Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:50:35.067Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-13T13:10:16.000Z",
            "title": "The Lessons of Developing Process Reward Models in Mathematical\n  Reasoning",
            "summary": "Process Reward Models (PRMs) emerge as a promising approach for process\nsupervision in mathematical reasoning of Large Language Models (LLMs), which\naim to identify and mitigate intermediate errors in the reasoning processes.\nHowever, the development of effective PRMs faces significant challenges,\nparticularly in data annotation and evaluation methodologies. In this paper,\nthrough extensive experiments, we demonstrate that commonly used Monte Carlo\n(MC) estimation-based data synthesis for PRMs typically yields inferior\nperformance and generalization compared to LLM-as-a-judge and human annotation\nmethods. MC estimation relies on completion models to evaluate current-step\ncorrectness, leading to inaccurate step verification. Furthermore, we identify\npotential biases in conventional Best-of-N (BoN) evaluation strategies for\nPRMs: (1) The unreliable policy models generate responses with correct answers\nbut flawed processes, leading to a misalignment between the evaluation criteria\nof BoN and the PRM objectives of process verification. (2) The tolerance of\nPRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a\nsignificant proportion of minimum scores concentrated on the final answer\nsteps, revealing the shift from process to outcome-based assessment in BoN\nOptimized PRMs. To address these challenges, we develop a consensus filtering\nmechanism that effectively integrates MC estimation with LLM-as-a-judge and\nadvocates a more comprehensive evaluation framework that combines\nresponse-level and step-level metrics. Based on the mechanisms, we\nsignificantly improve both model performance and data efficiency in the BoN\nevaluation and the step-wise error identification task. Finally, we release a\nnew state-of-the-art PRM that outperforms existing open-source alternatives and\nprovides practical guidelines for future research in building process\nsupervision models.",
            "upvotes": 39,
            "discussionId": "6785e602117627fe711f8e15"
        },
        "translation_title": "수학적 추론에서 프로세스 보상 모델 개발의 교훈",
        "purpose": "수학적 추론에서 프로세스 감독을 위한 효과적인 보상 모델 개발과 평가 방법론 개선",
        "method": [
            "광범위한 실험을 통해 일반적으로 사용되는 몬테카를로 추정(MC)이 PRM 성능이 열악하다는 것을 입증함.(we demonstrate that commonly used Monte Carlo (MC) estimation-based data synthesis for PRMs typically yields inferior performance)",
            "인간 주석 방법과 LLM-as-a-judge를 비교하여 데이터 효율성을 높임.(we identify that LLM-as-a-judge and human annotation methods provide better performance)",
            "Consensus filtering 메커니즘을 개발하여 MC 추정과 LLM-as-a-judge를 효과적으로 통합함.(we develop a consensus filtering mechanism that effectively integrates MC estimation with LLM-as-a-judge)"
        ],
        "conclusion": "새로 개발된 PRM은 기존 오픈소스 대안보다 우수한 성능을 보이며, 향후 프로세스 감독 모델 구축에 대한 실질적인 가이드라인을 제공함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2501.06425",
            "authors": [
                {
                    "_id": "6785ce62cb1fc2728334a5e2",
                    "user": {
                        "_id": "647bf082aba7062fe5c51ca9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg",
                        "isPro": false,
                        "fullname": "Yifan Zhang",
                        "user": "yifAI",
                        "type": "user"
                    },
                    "name": "Yifan Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-14T08:28:51.600Z",
                    "hidden": false
                },
                {
                    "_id": "6785ce62cb1fc2728334a5e3",
                    "name": "Yifeng Liu",
                    "hidden": false
                },
                {
                    "_id": "6785ce62cb1fc2728334a5e4",
                    "name": "Huizhuo Yuan",
                    "hidden": false
                },
                {
                    "_id": "6785ce62cb1fc2728334a5e5",
                    "user": {
                        "_id": "649014b91d71e55664838d2d",
                        "avatarUrl": "/avatars/f0e0f2830c5cb7428cbbc9634d95c34b.svg",
                        "isPro": false,
                        "fullname": "Zhen Qin",
                        "user": "zhenqincn",
                        "type": "user"
                    },
                    "name": "Zhen Qin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:51:32.418Z",
                    "hidden": true
                },
                {
                    "_id": "6785ce62cb1fc2728334a5e6",
                    "name": "Yang Yuan",
                    "hidden": false
                },
                {
                    "_id": "6785ce62cb1fc2728334a5e7",
                    "user": {
                        "_id": "64c039128e2612254356bba5",
                        "avatarUrl": "/avatars/06cc76feebba0cc80ebb8f4ff86f6d9b.svg",
                        "isPro": false,
                        "fullname": "Quanquan Gu",
                        "user": "thughost",
                        "type": "user"
                    },
                    "name": "Quanquan Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T08:52:03.941Z",
                    "hidden": false
                },
                {
                    "_id": "6785ce62cb1fc2728334a5e8",
                    "name": "Andrew Chi-Chih Yao",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-11T03:37:10.000Z",
            "title": "Tensor Product Attention Is All You Need",
            "summary": "Scaling language models to handle longer input sequences typically\nnecessitates large key-value (KV) caches, resulting in substantial memory\noverhead during inference. In this paper, we propose Tensor Product Attention\n(TPA), a novel attention mechanism that uses tensor decompositions to represent\nqueries, keys, and values compactly, significantly shrinking KV cache size at\ninference time. By factorizing these representations into contextual low-rank\ncomponents (contextual factorization) and seamlessly integrating with RoPE, TPA\nachieves improved model quality alongside memory efficiency. Based on TPA, we\nintroduce the Tensor ProducT ATTenTion Transformer (T6), a new model\narchitecture for sequence modeling. Through extensive empirical evaluation of\nlanguage modeling tasks, we demonstrate that T6 exceeds the performance of\nstandard Transformer baselines including MHA, MQA, GQA, and MLA across various\nmetrics, including perplexity and a range of renowned evaluation benchmarks.\nNotably, TPAs memory efficiency enables the processing of significantly longer\nsequences under fixed resource constraints, addressing a critical scalability\nchallenge in modern language models. The code is available at\nhttps://github.com/tensorgi/T6.",
            "upvotes": 31,
            "discussionId": "6785ce63cb1fc2728334a639"
        },
        "translation_title": "텐서 곱 어텐션만 필요하다",
        "purpose": "길어진 입력 시퀀스를 처리하면서 메모리 효율성을 개선하고자 함.",
        "method": [
            "Tensor Product Attention (TPA)라는 새로운 어텐션 메커니즘을 제안하고, 텐서 분해를 사용해 쿼리, 키, 값을 간결하게 표현함(we propose Tensor Product Attention (TPA), a novel attention mechanism that uses tensor decompositions to represent queries, keys, and values compactly).",
            "TPA를 사용해 Tensor ProducT ATTenTion Transformer (T6)라는 새로운 모델 아키텍처를 구축함(Based on TPA, we introduce the Tensor ProducT ATTenTion Transformer (T6), a new model architecture for sequence modeling).",
            "다양한 언어 모델링 작업에 대해 T6의 성능을 광범위하게 평가하여 기존의 여러 Transformer 기준 모델들을 초과하는 성능을 보임(Through extensive empirical evaluation of language modeling tasks, we demonstrate that T6 exceeds the performance of standard Transformer baselines including MHA, MQA, GQA, and MLA across various metrics)."
        ],
        "conclusion": "TPA의 메모리 효율성 덕분에 고정된 자원 제약 하에서도 훨씬 긴 시퀀스를 처리할 수 있게 되어, 현대 언어 모델의 중요한 확장성 문제를 해결함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2501.06173",
            "authors": [
                {
                    "_id": "678604c71f54791d52bebe30",
                    "user": {
                        "_id": "64b5ba6060274cbb296d6288",
                        "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
                        "isPro": false,
                        "fullname": "Junfei Xiao",
                        "user": "lambertxiao",
                        "type": "user"
                    },
                    "name": "Junfei Xiao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-14T08:28:41.422Z",
                    "hidden": false
                },
                {
                    "_id": "678604c71f54791d52bebe31",
                    "name": "Feng Cheng",
                    "hidden": false
                },
                {
                    "_id": "678604c71f54791d52bebe32",
                    "name": "Lu Qi",
                    "hidden": false
                },
                {
                    "_id": "678604c71f54791d52bebe33",
                    "name": "Liangke Gui",
                    "hidden": false
                },
                {
                    "_id": "678604c71f54791d52bebe34",
                    "name": "Jiepeng Cen",
                    "hidden": false
                },
                {
                    "_id": "678604c71f54791d52bebe35",
                    "name": "Zhibei Ma",
                    "hidden": false
                },
                {
                    "_id": "678604c71f54791d52bebe36",
                    "name": "Alan Yuille",
                    "hidden": false
                },
                {
                    "_id": "678604c71f54791d52bebe37",
                    "name": "Lu Jiang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-10T18:52:11.000Z",
            "title": "VideoAuteur: Towards Long Narrative Video Generation",
            "summary": "Recent video generation models have shown promising results in producing\nhigh-quality video clips lasting several seconds. However, these models face\nchallenges in generating long sequences that convey clear and informative\nevents, limiting their ability to support coherent narrations. In this paper,\nwe present a large-scale cooking video dataset designed to advance long-form\nnarrative generation in the cooking domain. We validate the quality of our\nproposed dataset in terms of visual fidelity and textual caption accuracy using\nstate-of-the-art Vision-Language Models (VLMs) and video generation models,\nrespectively. We further introduce a Long Narrative Video Director to enhance\nboth visual and semantic coherence in generated videos and emphasize the role\nof aligning visual embeddings to achieve improved overall video quality. Our\nmethod demonstrates substantial improvements in generating visually detailed\nand semantically aligned keyframes, supported by finetuning techniques that\nintegrate text and image embeddings within the video generation process.\nProject page: https://videoauteur.github.io/",
            "upvotes": 13,
            "discussionId": "678604d01f54791d52bec130"
        },
        "translation_title": "VideoAuteur: 긴 서사적 비디오 생성을 향하여",
        "purpose": "요리 분야에서 긴 서사적 생성을 지원하는 데이터셋과 방법론 개발",
        "method": [
            "요리 비디오에 특화된 대규모 데이터셋을 생성하고 이의 품질을 검증함(we present a large-scale cooking video dataset designed to advance long-form narrative generation in the cooking domain.)",
            "최신 Vision-Language Models와 비디오 생성 모델을 사용해 데이터셋의 시각적 충실성과 텍스트 캡션 정확성을 평가함(We validate the quality of our proposed dataset in terms of visual fidelity and textual caption accuracy using state-of-the-art Vision-Language Models (VLMs) and video generation models, respectively.)",
            "Long Narrative Video Director를 도입해 생성된 비디오의 시각적 및 의미적 일관성을 향상시킴(We further introduce a Long Narrative Video Director to enhance both visual and semantic coherence in generated videos.)"
        ],
        "conclusion": "이 방법은 시각적으로 세밀하고 의미적으로 정렬된 주요 프레임을 생성하는 데 상당한 향상을 보여줍니다.",
        "keywords": [
            "Video Generation",
            "Vision-Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2501.07572",
            "authors": [
                {
                    "_id": "6785df7a934f275b48366bdf",
                    "user": {
                        "_id": "644a4fbc2166258fccc664bc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
                        "isPro": false,
                        "fullname": "Jialong Wu",
                        "user": "callanwu",
                        "type": "user"
                    },
                    "name": "Jialong Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-14T08:28:45.818Z",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be0",
                    "name": "Wenbiao Yin",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be1",
                    "name": "Yong Jiang",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be2",
                    "user": {
                        "_id": "6643261b8876db14227eeb19",
                        "avatarUrl": "/avatars/67428c9e37a2273697c0547e1783ec6b.svg",
                        "isPro": false,
                        "fullname": "Zhenglin Wang",
                        "user": "wzl0228",
                        "type": "user"
                    },
                    "name": "Zhenglin Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T09:08:43.731Z",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be3",
                    "user": {
                        "_id": "647229256facfb01d8ae7b89",
                        "avatarUrl": "/avatars/2fc34d2739b28c1089b20e7a7fa40f0e.svg",
                        "isPro": false,
                        "fullname": "Xi Ze Kun",
                        "user": "ZekunXi",
                        "type": "user"
                    },
                    "name": "Zekun Xi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T09:08:51.642Z",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be4",
                    "user": {
                        "_id": "63d32cd7b734eaa4d4fa410b",
                        "avatarUrl": "/avatars/68acb80f62bc6493e1ad26506999b6c4.svg",
                        "isPro": false,
                        "fullname": "Runnan Fang",
                        "user": "Runnaning",
                        "type": "user"
                    },
                    "name": "Runnan Fang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T09:08:58.816Z",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be5",
                    "user": {
                        "_id": "64e821f2bddc5b1072b15c2e",
                        "avatarUrl": "/avatars/618b5a48f2fa62daff4e1922a9aa9e8b.svg",
                        "isPro": false,
                        "fullname": "zhoudeyu",
                        "user": "zhoudeyu",
                        "type": "user"
                    },
                    "name": "Deyu Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T09:09:13.637Z",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be6",
                    "user": {
                        "_id": "63a091e42fabbbb89991f5ce",
                        "avatarUrl": "/avatars/d55485b06461764c36c9edf9d6e8892c.svg",
                        "isPro": false,
                        "fullname": "pengjun xie",
                        "user": "xpjandy",
                        "type": "user"
                    },
                    "name": "Pengjun Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T09:09:20.633Z",
                    "hidden": false
                },
                {
                    "_id": "6785df7a934f275b48366be7",
                    "user": {
                        "_id": "635b8b6a37c6a2c12e2cce00",
                        "avatarUrl": "/avatars/229fb72180529141515d1df797b33709.svg",
                        "isPro": false,
                        "fullname": "Fei Huang",
                        "user": "hzhwcmhf",
                        "type": "user"
                    },
                    "name": "Fei Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-14T09:09:29.902Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-13T18:58:07.000Z",
            "title": "WebWalker: Benchmarking LLMs in Web Traversal",
            "summary": "Retrieval-augmented generation (RAG) demonstrates remarkable performance\nacross tasks in open-domain question-answering. However, traditional search\nengines may retrieve shallow content, limiting the ability of LLMs to handle\ncomplex, multi-layered information. To address it, we introduce WebWalkerQA, a\nbenchmark designed to assess the ability of LLMs to perform web traversal. It\nevaluates the capacity of LLMs to traverse a website's subpages to extract\nhigh-quality data systematically. We propose WebWalker, which is a multi-agent\nframework that mimics human-like web navigation through an explore-critic\nparadigm. Extensive experimental results show that WebWalkerQA is challenging\nand demonstrates the effectiveness of RAG combined with WebWalker, through the\nhorizontal and vertical integration in real-world scenarios.",
            "upvotes": 12,
            "discussionId": "6785df7c934f275b48366cff"
        },
        "translation_title": "WebWalker: LLM의 웹 탐색 성능 벤치마크",
        "purpose": "LLM이 웹 서브 페이지를 탐색해 고품질 데이터를 체계적으로 추출할 수 있는 능력 평가",
        "method": [
            "WebWalkerQA라는 벤치마크를 소개하여 LLM의 웹 탐색 능력을 평가함(To address it, we introduce WebWalkerQA, a benchmark designed to assess the ability of LLMs to perform web traversal.)",
            "WebWalker라는 다중 에이전트 프레임워크를 제안하여 인간과 유사한 웹 탐색을 모방함(We propose WebWalker, which is a multi-agent framework that mimics human-like web navigation through an explore-critic paradigm.)",
            "광범위한 실험 결과를 통해 WebWalkerQA의 도전성을 보여주고, RAG와의 결합 효과를 입증함(Extensive experimental results show that WebWalkerQA is challenging and demonstrates the effectiveness of RAG combined with WebWalker.)"
        ],
        "conclusion": "WebWalker는 실제 시나리오에서 웹 탐색 능력을 평가하는 데 효과적이며 RAG의 성능을 향상시키는 데 기여함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    }
]