[
    {
        "paper": {
            "id": "2412.17743",
            "authors": [
                {
                    "_id": "676d2c63310ca4eb397415fe",
                    "name": "Yiwen Hu",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb397415ff",
                    "name": "Huatong Song",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741600",
                    "name": "Jia Deng",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741601",
                    "name": "Jiapeng Wang",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741602",
                    "name": "Jie Chen",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741603",
                    "name": "Kun Zhou",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741604",
                    "name": "Yutao Zhu",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741605",
                    "name": "Jinhao Jiang",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741606",
                    "name": "Zican Dong",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741607",
                    "name": "Wayne Xin Zhao",
                    "hidden": false
                },
                {
                    "_id": "676d2c63310ca4eb39741608",
                    "name": "Ji-Rong Wen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-23T17:47:53.000Z",
            "title": "YuLan-Mini: An Open Data-efficient Language Model",
            "summary": "Effective pre-training of large language models (LLMs) has been challenging\ndue to the immense resource demands and the complexity of the technical\nprocesses involved. This paper presents a detailed technical report on\nYuLan-Mini, a highly capable base model with 2.42B parameters that achieves\ntop-tier performance among models of similar parameter scale. Our pre-training\napproach focuses on enhancing training efficacy through three key technical\ncontributions: an elaborate data pipeline combines data cleaning with data\nschedule strategies, a robust optimization method to mitigate training\ninstability, and an effective annealing approach that incorporates targeted\ndata selection and long context training. Remarkably, YuLan-Mini, trained on\n1.08T tokens, achieves performance comparable to industry-leading models that\nrequire significantly more data. To facilitate reproduction, we release the\nfull details of the data composition for each training phase. Project details\ncan be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.",
            "upvotes": 26,
            "discussionId": "676d2c65310ca4eb39741682"
        },
        "translation_title": "YuLan-Mini: 오픈 데이터 효율적인 언어 모델",
        "purpose": "대규모 언어 모델의 효과적인 사전 학습을 위한 데이터와 학습 효율성 향상",
        "method": [
            "정교한 데이터 파이프라인을 통해 데이터 정리와 스케줄 전략을 결합함(Our pre-training approach focuses on enhancing training efficacy through three key technical contributions: an elaborate data pipeline combines data cleaning with data schedule strategies.)",
            "훈련 불안정을 완화하기 위해 강력한 최적화 방법을 적용함(a robust optimization method to mitigate training instability.)",
            "타겟 데이터 선택과 장기 문맥 훈련을 포함한 효율적인 담금질 방식 사용함(an effective annealing approach that incorporates targeted data selection and long context training.)"
        ],
        "conclusion": "YuLan-Mini는 1.08T 토큰으로 학습하여 데이터 사용량이 많은 산업 선도 모델과 유사한 성능을 달성함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2412.17483",
            "authors": [
                {
                    "_id": "676a2a3ebce62ec5a02c4a66",
                    "user": {
                        "_id": "654c99d6e82a71cb487c2ecd",
                        "avatarUrl": "/avatars/480c883b587ed2e41e1e9661c844a938.svg",
                        "isPro": false,
                        "fullname": "ChenlongDeng",
                        "user": "ChenlongDeng",
                        "type": "user"
                    },
                    "name": "Chenlong Deng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-26T18:49:33.308Z",
                    "hidden": false
                },
                {
                    "_id": "676a2a3ebce62ec5a02c4a67",
                    "name": "Zhisong Zhang",
                    "hidden": false
                },
                {
                    "_id": "676a2a3ebce62ec5a02c4a68",
                    "name": "Kelong Mao",
                    "hidden": false
                },
                {
                    "_id": "676a2a3ebce62ec5a02c4a69",
                    "name": "Shuaiyi Li",
                    "hidden": false
                },
                {
                    "_id": "676a2a3ebce62ec5a02c4a6a",
                    "name": "Xinting Huang",
                    "hidden": false
                },
                {
                    "_id": "676a2a3ebce62ec5a02c4a6b",
                    "name": "Dong Yu",
                    "hidden": false
                },
                {
                    "_id": "676a2a3ebce62ec5a02c4a6c",
                    "name": "Zhicheng Dou",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-23T11:24:04.000Z",
            "title": "A Silver Bullet or a Compromise for Full Attention? A Comprehensive\n  Study of Gist Token-based Context Compression",
            "summary": "In this work, we provide a thorough investigation of gist-based context\ncompression methods to improve long-context processing in large language\nmodels. We focus on two key questions: (1) How well can these methods replace\nfull attention models? and (2) What potential failure patterns arise due to\ncompression? Through extensive experiments, we show that while gist-based\ncompression can achieve near-lossless performance on tasks like\nretrieval-augmented generation and long-document QA, it faces challenges in\ntasks like synthetic recall. Furthermore, we identify three key failure\npatterns: lost by the boundary, lost if surprise, and lost along the way. To\nmitigate these issues, we propose two effective strategies: fine-grained\nautoencoding, which enhances the reconstruction of original token information,\nand segment-wise token importance estimation, which adjusts optimization based\non token dependencies. Our work provides valuable insights into the\nunderstanding of gist token-based context compression and offers practical\nstrategies for improving compression capabilities.",
            "upvotes": 17,
            "discussionId": "676a2a3fbce62ec5a02c4ace"
        },
        "translation_title": "전체 주의를 위한 은총의 해법인가,妥协인가? Gist Token 기반의 문맥 압축에 대한 종합 연구",
        "purpose": "Gist 기반 문맥 압축 기법을 통해 대형 언어 모델에서 긴 문맥 처리를 개선하려는 목표",
        "method": [
            "Gist 기반의 문맥 압축 기법이 전체 주의 모델을 대체할 수 있는지를 평가함(We focus on two key questions: (1) How well can these methods replace full attention models?)",
            "압축으로 인한 잠재적 실패 패턴을 파악하고 실험을 통해 분석함(we identify three key failure patterns: lost by the boundary, lost if surprise, and lost along the way.)",
            "문맥 압축의 문제를 완화하기 위해 세분화된 자동 인코딩과 토큰 의존성 기반의 중요도 추정을 제안함(we propose two effective strategies: fine-grained autoencoding and segment-wise token importance estimation.)"
        ],
        "conclusion": "Gist 기반 문맥 압축 기법은 뛰어난 성능을 보여주지만, 특정 작업에서의 한계와 실패 패턴을 이해하고 극복할 수 있는 실질적인 전략을 제시함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2412.18072",
            "authors": [
                {
                    "_id": "676e9cfc11998b72ab00be60",
                    "name": "Wan-Cyuan Fan",
                    "hidden": false
                },
                {
                    "_id": "676e9cfc11998b72ab00be61",
                    "name": "Tanzila Rahman",
                    "hidden": false
                },
                {
                    "_id": "676e9cfc11998b72ab00be62",
                    "name": "Leonid Sigal",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-24T00:59:16.000Z",
            "title": "MMFactory: A Universal Solution Search Engine for Vision-Language Tasks",
            "summary": "With advances in foundational and vision-language models, and effective\nfine-tuning techniques, a large number of both general and special-purpose\nmodels have been developed for a variety of visual tasks. Despite the\nflexibility and accessibility of these models, no single model is able to\nhandle all tasks and/or applications that may be envisioned by potential users.\nRecent approaches, such as visual programming and multimodal LLMs with\nintegrated tools aim to tackle complex visual tasks, by way of program\nsynthesis. However, such approaches overlook user constraints (e.g.,\nperformance / computational needs), produce test-time sample-specific solutions\nthat are difficult to deploy, and, sometimes, require low-level instructions\nthat maybe beyond the abilities of a naive user. To address these limitations,\nwe introduce MMFactory, a universal framework that includes model and metrics\nrouting components, acting like a solution search engine across various\navailable models. Based on a task description and few sample input-output pairs\nand (optionally) resource and/or performance constraints, MMFactory can suggest\na diverse pool of programmatic solutions by instantiating and combining\nvisio-lingual tools from its model repository. In addition to synthesizing\nthese solutions, MMFactory also proposes metrics and benchmarks performance /\nresource characteristics, allowing users to pick a solution that meets their\nunique design constraints. From the technical perspective, we also introduced a\ncommittee-based solution proposer that leverages multi-agent LLM conversation\nto generate executable, diverse, universal, and robust solutions for the user.\nExperimental results show that MMFactory outperforms existing methods by\ndelivering state-of-the-art solutions tailored to user problem specifications.\nProject page is available at https://davidhalladay.github.io/mmfactory_demo.",
            "upvotes": 4,
            "discussionId": "676e9cfd11998b72ab00bfe8"
        },
        "translation_title": "MMFactory: 비전-언어 작업을 위한 보편적인 솔루션 검색 엔진",
        "purpose": "다양한 비전-언어 작업을 효율적으로 처리할 수 있는 보편적인 솔루션 제공",
        "method": [
            "사용자 제약 조건을 고려하여 다양한 모델과 메트릭 라우팅 구성 요소를 포함한 MMFactory 프레임워크를 개발함(we introduce MMFactory, a universal framework that includes model and metrics routing components).",
            "작업 설명과 예제 입력-출력 쌍을 기반으로 많은 프로그램적 솔루션을 제안함(MMFactory can suggest a diverse pool of programmatic solutions by instantiating and combining visio-lingual tools from its model repository).",
            "다양하고 견고한 솔루션을 생성하기 위해 다중 에이전트 LLM 대화를 활용하는 위원회 기반 솔루션 제안자를 도입함(we also introduced a committee-based solution proposer that leverages multi-agent LLM conversation)."
        ],
        "conclusion": "실험 결과 MMFactory는 사용자 문제에 맞춘 최첨단 솔루션을 제공하며 기존 방법보다 우수한 성능을 나타냄.",
        "keywords": [
            "Multimodal Learning",
            "Vision-Language Models",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2412.18176",
            "authors": [
                {
                    "_id": "676e9d9d8126645611b73ecb",
                    "name": "Yucong Luo",
                    "hidden": false
                },
                {
                    "_id": "676e9d9d8126645611b73ecc",
                    "name": "Qitao Qin",
                    "hidden": false
                },
                {
                    "_id": "676e9d9d8126645611b73ecd",
                    "name": "Hao Zhang",
                    "hidden": false
                },
                {
                    "_id": "676e9d9d8126645611b73ece",
                    "name": "Mingyue Cheng",
                    "hidden": false
                },
                {
                    "_id": "676e9d9d8126645611b73ecf",
                    "name": "Ruiran Yan",
                    "hidden": false
                },
                {
                    "_id": "676e9d9d8126645611b73ed0",
                    "name": "Kefan Wang",
                    "hidden": false
                },
                {
                    "_id": "676e9d9d8126645611b73ed1",
                    "name": "Jie Ouyang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-24T05:23:13.000Z",
            "title": "Molar: Multimodal LLMs with Collaborative Filtering Alignment for\n  Enhanced Sequential Recommendation",
            "summary": "Sequential recommendation (SR) systems have evolved significantly over the\npast decade, transitioning from traditional collaborative filtering to deep\nlearning approaches and, more recently, to large language models (LLMs). While\nthe adoption of LLMs has driven substantial advancements, these models\ninherently lack collaborative filtering information, relying primarily on\ntextual content data neglecting other modalities and thus failing to achieve\noptimal recommendation performance. To address this limitation, we propose\nMolar, a Multimodal large language sequential recommendation framework that\nintegrates multiple content modalities with ID information to capture\ncollaborative signals effectively. Molar employs an MLLM to generate unified\nitem representations from both textual and non-textual data, facilitating\ncomprehensive multimodal modeling and enriching item embeddings. Additionally,\nit incorporates collaborative filtering signals through a post-alignment\nmechanism, which aligns user representations from content-based and ID-based\nmodels, ensuring precise personalization and robust performance. By seamlessly\ncombining multimodal content with collaborative filtering insights, Molar\ncaptures both user interests and contextual semantics, leading to superior\nrecommendation accuracy. Extensive experiments validate that Molar\nsignificantly outperforms traditional and LLM-based baselines, highlighting its\nstrength in utilizing multimodal data and collaborative signals for sequential\nrecommendation tasks. The source code is available at\nhttps://anonymous.4open.science/r/Molar-8B06/.",
            "upvotes": 2,
            "discussionId": "676e9d9d8126645611b73f18"
        },
        "translation_title": "Molar: 향상된 순차 추천을 위한 협업 필터링 정렬을 갖춘 다중 모달 LLM",
        "purpose": "순차 추천 시스템에서 협업 필터링 정보를 통합하여 최적의 추천 성능을 달성하는 것이 목표임",
        "method": [
            "여러 콘텐츠 모달리티와 ID 정보를 통합하는 다중 모달 대규모 언어 모델 프레임워크 Molar를 제안함(To address this limitation, we propose Molar, a Multimodal large language sequential recommendation framework that integrates multiple content modalities with ID information to capture collaborative signals effectively.)",
            "MLLM을 사용해 텍스트와 비텍스트 데이터로부터 통합된 아이템 표현을 생성함(Molar employs an MLLM to generate unified item representations from both textual and non-textual data, facilitating comprehensive multimodal modeling and enriching item embeddings.)",
            "후처리 정렬 메커니즘을 통해 콘텐츠 기반 모델과 ID 기반 모델의 사용자 표현을 정렬함(Additionally, it incorporates collaborative filtering signals through a post-alignment mechanism, which aligns user representations from content-based and ID-based models, ensuring precise personalization and robust performance.)"
        ],
        "conclusion": "Molar는 다중 모달 데이터와 협업 신호를 효과적으로 활용하여 우수한 추천 정확도를 달성하며, 기존의 방법들보다 월등한 성능을 보임.",
        "keywords": [
            "Large Language Models",
            "Multimodal Learning",
            "Collaborative Filtering"
        ]
    }
]